{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import spacy\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "from nltk import sent_tokenize\n",
    "import xlrd\n",
    "\n",
    "# nlp = spacy.load('en')\n",
    "# doc = nlp(\"I cured the illness. The illness was cured by me. A red cup. I ran quickly.\")\n",
    "# doc_list = list(doc)\n",
    "# def flatten_subtree(st):\n",
    "#    return ''.join([w.text_with_ws for w in list(st)]).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speaker_ids = speaker_ids\n",
    "# xxx\n",
    "\n",
    "speaker_ids = [\"P1\", \"N1\", \"D1\", \"D2\", \"R1\", \"R2\"]\n",
    "speaker_ids = [x.lower() for x in speaker_ids]\n",
    "speaker_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create placeholders for results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Aggregate mentions of clinical concept (i.e. 1 number per consultation)\n",
    "clin_concepts_number_per_consultation_speaker = {}\n",
    "\n",
    "### Aggregate mentions of each clinical classification (separately) (i.e. >1 number per consultation)\n",
    "clin_classes_type_number_per_consultation_speaker = {}\n",
    "\n",
    "### Everything else in 1 large dictionary\n",
    "per_speaker = {}\n",
    "per_speaker['positive_sentiment_count']    = {}\n",
    "per_speaker['negative_sentiment_count']    = {}\n",
    "per_speaker['active_count']                = {}\n",
    "per_speaker['passive_count']               = {}\n",
    "\n",
    "per_speaker['pos_verb_count']                    = {}\n",
    "per_speaker['pos_personal_pronoun_count']        = {}\n",
    "per_speaker['pos_adverb_count']                  = {}\n",
    "per_speaker['pos_adjective_count']               = {}\n",
    "\n",
    "\n",
    "list_dict_parts = [\"positive_sentiment_count\", \"negative_sentiment_count\",\n",
    "             \"active_count\",              \"passive_count\", \n",
    "             \"pos_verb_count\",      \"pos_personal_pronoun_count\",     \n",
    "             \"pos_adverb_count\",    \"pos_adjective_count\" \n",
    "             ]\n",
    "\n",
    "\n",
    "for x in list_dict_parts:\n",
    "    type(per_speaker[x])\n",
    "    print(per_speaker[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spacy preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dictionary linking each clinical concept to its classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i create_clin_concepts_dict.py\n",
    "\n",
    "clin_concepts_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the tokeniser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run -i sentiment_tokenize.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the 2 x lists of positive & negative words from General Inquirer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i sentiment_general_inquirer_import.ipynb\n",
    "\n",
    "print(\"Positive sample\")\n",
    "positive[:5]\n",
    "positive[-5:]\n",
    "\n",
    "print()\n",
    "print(\"Negative sample\")\n",
    "negative[:5]\n",
    "negative[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of all classes (for dictionary of count of classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_classes = ['BIOSUB',\n",
    "    'BODYLOC',\n",
    "    'BODYMEAS',\n",
    "    'DDF',\n",
    "    'DIAGPROC',\n",
    "    'DISORDER',\n",
    "    'DOSEUNIT',\n",
    "    'DRT',\n",
    "    'DRUG',\n",
    "    'FREQ',\n",
    "    'LABTEST',\n",
    "    'NUM',\n",
    "    'PROBLEM',\n",
    "    'THERPROCDEV',\n",
    "    'TK',\n",
    "    'TOD',\n",
    "    'TUNIT',\n",
    "    'UNIT',\n",
    "    'RUT']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### START LOOP HERE - OVER EACH TRANSCRIPT SEPARATELY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PREAMBLE:\n",
    "counter = 0\n",
    "folder  = \"sentiment_text_data\"\n",
    "number_of_files = len(os.listdir(folder))\n",
    "print(\"Number of files in the directory: {}\".format(number_of_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(list_dict_parts)\n",
    "\n",
    "for x in list_dict_parts:\n",
    "    print(x)\n",
    "    type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INITIATE LOOP PER FILE:\n",
    "while counter < number_of_files:\n",
    "\n",
    "    ### number of times any clinical concept mentioned: add to master dictionary for all transcripts\n",
    "    clin_concepts_number_per_consultation_speaker[str(counter+1)] =  {}\n",
    "    \n",
    "    ### \"per_speaker\" dictionary for capturing everything EXCEPT the clin concepts per speaker.\n",
    "    number_consult = str(counter+1)\n",
    "    for x in list_dict_parts:\n",
    "        per_speaker[x][number_consult] =  {}\n",
    "        type(per_speaker[x][number_consult])\n",
    "\n",
    "### INITIATE LOOP PER SPEAKER:\n",
    "    for speaker_id in speaker_ids:\n",
    "\n",
    "### print file name / number / speaker_id:\n",
    "        file = os.listdir(folder)[counter]\n",
    "        print()\n",
    "        print(\"File number: {}\".format(counter + 1))\n",
    "        print(\"File name: {}\".format(file))\n",
    "        print(\"Speaker ID: {}\".format(speaker_id))\n",
    "        print()\n",
    "\n",
    "### XXX XXX SORT OUT INDENTS BELOW.\n",
    "### keep the lines relating to speaker of interest\n",
    "        lines_to_keep  =  []\n",
    "        with open(file, \"r\") as f:\n",
    "            for line in f.readlines():\n",
    "                print(\"This is a line of text\")\n",
    "                line = line.lower()\n",
    "                print(line)\n",
    "                print(type(line))\n",
    "                if line.startswith(speaker_id):\n",
    "                    lines_to_keep.append(line)\n",
    "\n",
    "    \n",
    "########################### Write all the lines in our list to a new text file called \"speaker.txt\"\n",
    "        with open(\"speaker.txt\", \"w\") as f:\n",
    "            for line in lines_to_keep:\n",
    "                f.write(line)\n",
    "\n",
    "\n",
    "########################### Open the text file \"speaker.txt\" & tokenise into \"tokens\" (this removes punctuation such as ':' )\n",
    "        speaker_opened = open(\"speaker.txt\")  \n",
    "        speaker_read =   speaker_opened.read()\n",
    "        tokens  =   tokenize_only(speaker_read)\n",
    "        speaker_sent_tokenize  = sent_tokenize(speaker_read)\n",
    "    \n",
    "        type(speaker_opened)\n",
    "        type(speaker_read)\n",
    "        type(tokens)\n",
    "        type(speaker_sent_tokenize)\n",
    "\n",
    "\n",
    "    ########################### Remove \"n1\" / \"d1\" / \"p1\" etc. from the list obviously:\n",
    "        tokens  =  list(filter((speaker_id.lower).__ne__, tokens))\n",
    "\n",
    "        print(\"Check: First 100 tokens\")\n",
    "        tokens\n",
    "        tokens[:100]\n",
    "\n",
    "        print(\"Check: Last 100 tokens\")\n",
    "        tokens[-100:]\n",
    "        \n",
    "        ######  Placeholder: Dictionary to count no. times each class occurs.\n",
    "        ######  (will insert into \"clin_classes_type_number_per_consultation\" for every consultation)\n",
    "        count_each_class_type_speaker = {}\n",
    "        count_each_class_type_speaker[speaker_id] = {}\n",
    "        for x in list_classes:\n",
    "            count_each_class_type_speaker[speaker_id][x] = 0\n",
    "        \n",
    "            ### \"per_speaker\" dictionary for capturing everything EXCEPT the clin concepts per speaker.\n",
    "        for x in list_dict_parts:\n",
    "            per_speaker[x][number_consult][speaker_id] =  0\n",
    "\n",
    "        # XXX - just so it runs quickly during development.\n",
    "        my_text_strings = tokens[0:400]\n",
    "        \n",
    "        # my_text_strings  =  tokens\n",
    "\n",
    "        \n",
    "        ### run notebook code for: POS / positive and negative sentiment / active and passive run.\n",
    "        % run -i loop_per_speaker_inner_loop.ipynb\n",
    "        print(\"per_speaker['positive_sentiment_count']\")\n",
    "        print(per_speaker['positive_sentiment_count'])\n",
    "        print(\"per_speaker['negative_sentiment_count']\")\n",
    "        print(per_speaker['negative_sentiment_count'])\n",
    "        \n",
    "        ### placeholders for results (variables relate to this combo of consultation / speaker)\n",
    "        classifications_length = 0\n",
    "        concepts_length        = 0\n",
    "        all_classifications_consultation_prelim = []\n",
    "    \n",
    "        ### counter for the \"for\" loop over each token below\n",
    "        token_number = 1\n",
    "    \n",
    "        ### loop over each token\n",
    "        for mystring in my_text_strings:\n",
    "            \n",
    "            ### store the class & concept (if the token is a \"clinical concept\")\n",
    "            classifications_consultation = [value for key, value in clin_concepts_dict.items() if mystring == key.lower()]\n",
    "            concepts_consultation        = [key for key, value in clin_concepts_dict.items() if mystring == key.lower()]       \n",
    "    \n",
    "            ### update the number of clinical concepts per consultation / speaker\n",
    "            classifications_length += len(classifications_consultation)\n",
    "            concepts_length        += len(concepts_consultation)\n",
    "            \n",
    "            ### add the \"classification\" (e.g. treatment / problem) to the list of classifications for the specific transcript\n",
    "            if classifications_consultation !=  []:\n",
    "                all_classifications_consultation_prelim.extend(classifications_consultation)\n",
    "            \n",
    "            ### just a simple progress indicator for the token loop\n",
    "            if token_number % 200 == 0:\n",
    "                print(\"Progress tracking: File number {}, Token number {} (of a total of {} tokens)\".format(counter+1, token_number, len(tokens)))\n",
    "            \n",
    "            ### and back to start of token loop\n",
    "            token_number += 1\n",
    "        \n",
    "        \n",
    "        print(\"\")\n",
    "        print(\"all_classifications_consultation_prelim: before split on hyphen\")\n",
    "        print(all_classifications_consultation_prelim[0:50])\n",
    "    \n",
    "        ### some tokens have multiple classes (e.g. \"treatment-problem\") - split on the hyphen to account for each class separately.\n",
    "        all_classifications_consultation_prelim  = [i.split('-', 10)[:] for i in all_classifications_consultation_prelim]\n",
    "    \n",
    "        ### check that the split occurred ok and nothing is missing.\n",
    "        print(\"\")\n",
    "        print(\"all_classifications_consultation_prelim: after split on hyphen\")\n",
    "        all_classifications_consultation_prelim[0:50]\n",
    "    \n",
    "        ### the final container for the classes for a consultation / speaker (i.e. put it in the right List form)\n",
    "        all_classifications_consultation_final = []\n",
    "        for x in all_classifications_consultation_prelim:\n",
    "            all_classifications_consultation_final.extend(x)\n",
    "        ### just show the first 20 (this confirms the content and the appropriate object type)\n",
    "        all_classifications_consultation_final[0:20]\n",
    "    \n",
    "        ######### Freq Each Class Type: put into Dictionary (for this particular consultation / speaker)\n",
    "        for x in all_classifications_consultation_final:\n",
    "            count_each_class_type_speaker[speaker_id][x] +=1 \n",
    "        print()\n",
    "        print(\"count_each_class_type: i.e. the dictionary containing the number of each class for a consultation\")\n",
    "        count_each_class_type_speaker\n",
    "            ## number of times each type of clinical classification mentioned: add to master dictionary for all transcripts\n",
    "        clin_classes_type_number_per_consultation_speaker[str(counter+1)] = count_each_class_type_speaker            \n",
    "        \n",
    "        ######### Number of Concepts: put into Dictionary (for this particular consultation / speaker)\n",
    "        print()\n",
    "        print(\"classifications_length: for one transcript / speaker\")\n",
    "        classifications_length\n",
    "        print()\n",
    "        print(\"concepts_length: for one transcript\")\n",
    "        concepts_length\n",
    "        ### number of times any clinical concept mentioned: add to master dictionary for all transcripts\n",
    "        clin_concepts_number_per_consultation_speaker[str(counter+1)][speaker_id] = concepts_length\n",
    "\n",
    "\n",
    "    counter  +=  1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After loop -  look at results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Number of clinical concepts per consultation\")\n",
    "clin_concepts_number_per_consultation_speaker\n",
    "\n",
    "print(\"How many times each classification appeared in each transcript\")\n",
    "clin_classes_type_number_per_consultation_speaker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo: method for adding new keys to a dictionary in a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speak_ids = [\"a\", \"b\", \"c\"]\n",
    "clin_classes_type_number_per_consultation_speaker = {}\n",
    "\n",
    "for x in speak_ids:\n",
    "    final = \"List_\" + x\n",
    "    \n",
    "    clin_classes_type_number_per_consultation_speaker[final] = {}\n",
    "    clin_classes_type_number_per_consultation_speaker[final][\"result_a\"] = 1\n",
    "    clin_classes_type_number_per_consultation_speaker[final][\"result_b\"] = 2\n",
    "\n",
    "clin_classes_type_number_per_consultation_speaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### another little demo of how to automate the creation of dictionary components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_ids = [\"a\", \"b\"]\n",
    "\n",
    "list_classes = ['BIOSUB',\n",
    "    'BODYLOC',\n",
    "    'BODYMEAS',\n",
    "    'UNIT']\n",
    "\n",
    "count_each_class_type_speaker = {}\n",
    "\n",
    "for speaker_id in speaker_ids:\n",
    "        count_each_class_type_speaker[speaker_id] = {}\n",
    "        for x in list_classes:\n",
    "            count_each_class_type_speaker[speaker_id][x] = 0\n",
    "count_each_class_type_speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
