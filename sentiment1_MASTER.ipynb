{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal file.\n",
    "\n",
    "## Part 1: prepare for loop over all .txt files\n",
    "1. import dependencies\n",
    "2. set up Stanford dependency parser.\n",
    "3. create the positive & negative word lists:  general_inquirer_import.ipynb\n",
    "4. create functions for: 1: tokenize // 2: tokenize & stem\n",
    "5. create Empty Lists for number of positive words, negative words, active voice, passive voice, etc.\n",
    "## Part 2: LOOP - once for every .txt file\n",
    "1. Sentiment analysis (open & tokenize text file) <br>\n",
    "ii  Count aggregate number of all positive and negative items <br>\n",
    "iii Show all pos and neg words for this text file. <br>\n",
    "iv  construct set // frequency of all pos and neg words in all of the text files. <br>\n",
    "2. Turn-taking <br>\n",
    "ii.  No. participants <br>\n",
    "iii. No. turns per speaker (i.e. just count lines starting with N1 etc) <br>\n",
    "iv.  Per speaker: run another loop (sentiment3_each_speaker.ipynb) <br>\n",
    "\n",
    "## Part 3: After loop - summarise results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Words to match on\n",
    "list_words = [\"i\", \"you\", \"we\", \"decide\", \"decision\", \"option\", \"options\"] \n",
    "\n",
    "#### Phrases to match on\n",
    "list_phrases = []\n",
    "\n",
    "#### Speaker identifiers (these are followed by a colon at the start of each turn)\n",
    "speakers = [\"P1\", \"N1\", \"D1\", \"D2\", \"R1\", \"R2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.parse.stanford import StanfordDependencyParser\n",
    "from nltk.parse.stanford import StanfordParser\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import codecs\n",
    "from sklearn import feature_extraction\n",
    "import mpld3\n",
    "from matplotlib import pyplot as plt\n",
    "from itertools import zip_longest\n",
    "import spacy\n",
    "from collections import Counter\n",
    "from nltk import sent_tokenize\n",
    "from nltk import word_tokenize\n",
    "import io\n",
    "import pandas as pd\n",
    "import xlrd\n",
    "import pprint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### configure to display results of all content of cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### display the environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Padhraig\\OneDrive\\Python\\inca python code\\Sentiment_Analysis;C:\\Users\\Padhraig\\Documents\\INCA data\\inca python code\\Sentiment_Analysis;C:\\ProgramData\\Anaconda3;C:\\ProgramData\\Anaconda3\\Scripts;C:\\ProgramData\\Anaconda3\\pkgs\\python-3.6.2-h6679aeb_11;C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\stanford-corenlp-full-2017-06-09;C:\\Users\\Padhraig\\OneDrive\\Python\\inca python code;C:\\Users\\Padhraig\\OneDrive\\Python\\python-conversational-alignment-master\\stanford-postagger-2015-04-20;\n"
     ]
    }
   ],
   "source": [
    "print(os.environ['CLASSPATH'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create containers for results. i.e. link participant identifiers with metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E.g. if utterances / paragraphs start with: Doctor1\n",
    "                                            Patient1\n",
    "Create list as:\n",
    "speaker_list = [Doctor1:, Patient1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print Dictionary Contents\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Num_turns_D1': 0.0,\n",
       " 'Num_turns_D2': 0.0,\n",
       " 'Num_turns_N1': 0.0,\n",
       " 'Num_turns_P1': 0.0,\n",
       " 'Num_turns_R1': 0.0,\n",
       " 'Num_turns_R2': 0.0,\n",
       " 'Num_words_D1': 0.0,\n",
       " 'Num_words_D2': 0.0,\n",
       " 'Num_words_N1': 0.0,\n",
       " 'Num_words_P1': 0.0,\n",
       " 'Num_words_R1': 0.0,\n",
       " 'Num_words_R2': 0.0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = [\"Num_turns_\", \"Num_words_\"]\n",
    "### \"speakers\" list was produced already.\n",
    "\n",
    "metrics_speaker = []\n",
    "\n",
    "for a in metrics:\n",
    "    for x in speakers:\n",
    "        full = a + x\n",
    "        metrics_speaker.append(full)\n",
    "\n",
    "# Create dictionary\n",
    "values = np.zeros(len(metrics_speaker))\n",
    "metrics_speaker_dict  = dict(zip(metrics_speaker, values))\n",
    "\n",
    "print(\"Print Dictionary Contents\")\n",
    "metrics_speaker_dict\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spacy preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: I\n",
      "Tag: PRP\n",
      "Head: cured\n",
      "Dependency relation: nsubj\n",
      "Children: []\n",
      "\n",
      "Word: cured\n",
      "Tag: VBD\n",
      "Head: cured\n",
      "Dependency relation: ROOT\n",
      "Children: [I, illness, .]\n",
      "\n",
      "Word: the\n",
      "Tag: DT\n",
      "Head: illness\n",
      "Dependency relation: det\n",
      "Children: []\n",
      "\n",
      "Word: illness\n",
      "Tag: NN\n",
      "Head: cured\n",
      "Dependency relation: dobj\n",
      "Children: [the]\n",
      "\n",
      "Word: .\n",
      "Tag: .\n",
      "Head: cured\n",
      "Dependency relation: punct\n",
      "Children: []\n",
      "\n",
      "Word: The\n",
      "Tag: DT\n",
      "Head: illness\n",
      "Dependency relation: det\n",
      "Children: []\n",
      "\n",
      "Word: illness\n",
      "Tag: NN\n",
      "Head: cured\n",
      "Dependency relation: nsubjpass\n",
      "Children: [The]\n",
      "\n",
      "Word: was\n",
      "Tag: VBD\n",
      "Head: cured\n",
      "Dependency relation: auxpass\n",
      "Children: []\n",
      "\n",
      "Word: cured\n",
      "Tag: VBN\n",
      "Head: cured\n",
      "Dependency relation: ROOT\n",
      "Children: [illness, was, by, .]\n",
      "\n",
      "Word: by\n",
      "Tag: IN\n",
      "Head: cured\n",
      "Dependency relation: agent\n",
      "Children: [me]\n",
      "\n",
      "Word: me\n",
      "Tag: PRP\n",
      "Head: by\n",
      "Dependency relation: pobj\n",
      "Children: []\n",
      "\n",
      "Word: .\n",
      "Tag: .\n",
      "Head: cured\n",
      "Dependency relation: punct\n",
      "Children: []\n",
      "\n",
      "Word: A\n",
      "Tag: DT\n",
      "Head: cup\n",
      "Dependency relation: det\n",
      "Children: []\n",
      "\n",
      "Word: red\n",
      "Tag: JJ\n",
      "Head: cup\n",
      "Dependency relation: amod\n",
      "Children: []\n",
      "\n",
      "Word: cup\n",
      "Tag: NN\n",
      "Head: cup\n",
      "Dependency relation: ROOT\n",
      "Children: [A, red, .]\n",
      "\n",
      "Word: .\n",
      "Tag: .\n",
      "Head: cup\n",
      "Dependency relation: punct\n",
      "Children: []\n",
      "\n",
      "Word: I\n",
      "Tag: PRP\n",
      "Head: ran\n",
      "Dependency relation: nsubj\n",
      "Children: []\n",
      "\n",
      "Word: ran\n",
      "Tag: VBD\n",
      "Head: ran\n",
      "Dependency relation: ROOT\n",
      "Children: [I, quickly, .]\n",
      "\n",
      "Word: quickly\n",
      "Tag: RB\n",
      "Head: ran\n",
      "Dependency relation: advmod\n",
      "Children: []\n",
      "\n",
      "Word: .\n",
      "Tag: .\n",
      "Head: ran\n",
      "Dependency relation: punct\n",
      "Children: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"I cured the illness. The illness was cured by me. A red cup. I ran quickly.\")\n",
    "\n",
    "counter = 0\n",
    "\n",
    "while counter < len(list(doc.sents)):\n",
    "    for word in list(doc.sents)[counter]:\n",
    "        print(\"Word:\", word.text)     \n",
    "        print(\"Tag:\", word.tag_)\n",
    "        print(\"Head:\", word.head.text)\n",
    "        print( \"Dependency relation:\", word.dep_)\n",
    "        print( \"Children:\", list(word.children))\n",
    "        print(\"\")\n",
    "    counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten_subtree(st):\n",
    "    return ''.join([w.text_with_ws for w in list(st)]).strip()\n",
    "\n",
    "# With this function in our toolbox, we can write a loop that prints out the subtree for each word in a sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjects_list = []\n",
    "for word in doc:\n",
    "    if word.dep_ == ('nsubj', 'nsubjpass'):\n",
    "        subjects_list.append(flatten_subtree(word.subtree))\n",
    "subjects_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'I']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['The illness']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsubj_subjects = []\n",
    "nsubj_count    = 0\n",
    "for word in doc:\n",
    "    if word.dep_ == ('nsubj'):\n",
    "        nsubj_count += 1\n",
    "        nsubj_subjects.append(flatten_subtree(word.subtree))\n",
    "nsubj_subjects\n",
    "nsubj_count\n",
    "\n",
    "nsubjpass_subjects = []\n",
    "nsubjpass_count = 0\n",
    "for word in doc:\n",
    "    if word.dep_ == ('nsubjpass'):\n",
    "        nsubjpass_count += 1\n",
    "        nsubjpass_subjects.append(flatten_subtree(word.subtree))\n",
    "nsubjpass_subjects\n",
    "nsubjpass_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the 2 x lists of positive & negative words from General Inquirer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run sentiment5_general_inquirer_import.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### print sample of first and last positive & negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive sample\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['advantage', 'stylish', 'appease', 'welfare', 'civility']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['exuberance', 'benefactor', 'conjure', 'steadfastness', 'standardize']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Negative sample\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['pry', 'repulse', 'shoot', 'deprive', 'temper']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['illegality', 'uninformed', 'treachery', 'break', 'unreasonable']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Positive sample\")\n",
    "positive[:5]\n",
    "positive[-5:]\n",
    "\n",
    "print()\n",
    "print(\"Negative sample\")\n",
    "negative[:5]\n",
    "negative[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define tokenizer and stemmer functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run -i sentiment_tokenize.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assert it is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenize_only\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['hi', 'my', 'friends']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "open_and_tokenize\n",
      "\n",
      "File number: 1\n",
      "File name: 1_1 PR.txt\n",
      "\n",
      "Open file and display 'type'\n",
      "\n",
      "Read file and display 'type'\n",
      "\n",
      "Tokenise file and display 'type'\n",
      "\n",
      "Just show the first & last 10 words of the main dialogue text file\n",
      "These are first 10 words:\n",
      "scenario\n",
      "pos\n",
      "aaa\n",
      "d1\n",
      "it\n",
      "s\n",
      "going\n",
      "a\n",
      "little\n",
      "bit\n",
      "These are last 10 words:\n",
      "pr43\n",
      "pr44\n",
      "pr45\n",
      "pr46\n",
      "pr47\n",
      "pr48\n",
      "pr49\n",
      "pr50\n",
      "pr51\n",
      "1_1.mp3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['scenario',\n",
       " 'pos',\n",
       " 'aaa',\n",
       " 'd1',\n",
       " 'it',\n",
       " 's',\n",
       " 'going',\n",
       " 'a',\n",
       " 'little',\n",
       " 'bit',\n",
       " 'fast',\n",
       " 'alright',\n",
       " 'can',\n",
       " 'i',\n",
       " 'have',\n",
       " 'a',\n",
       " 'listen',\n",
       " 'to',\n",
       " 'the',\n",
       " 'back',\n",
       " 'of',\n",
       " 'the',\n",
       " 'chest',\n",
       " 'there',\n",
       " 'at',\n",
       " 'the',\n",
       " 'at',\n",
       " 'at',\n",
       " 'the',\n",
       " 'breathing',\n",
       " 'p1',\n",
       " 'okay.',\n",
       " 'd1',\n",
       " 'if',\n",
       " 'you',\n",
       " 'don',\n",
       " 't',\n",
       " 'mind',\n",
       " 'we',\n",
       " 'll',\n",
       " 'just',\n",
       " 'sit',\n",
       " 'you',\n",
       " 'forward',\n",
       " 'there.',\n",
       " 'n1',\n",
       " 'we',\n",
       " 'll',\n",
       " 'just',\n",
       " 'sit',\n",
       " 'you',\n",
       " 'forward',\n",
       " 'there',\n",
       " 'okay',\n",
       " 'one',\n",
       " 'two',\n",
       " 'three',\n",
       " 'off',\n",
       " 'you',\n",
       " 'go',\n",
       " 'that',\n",
       " 's',\n",
       " 'it',\n",
       " 'd1',\n",
       " 'if',\n",
       " 'you',\n",
       " 'nice',\n",
       " 'deep',\n",
       " 'breaths',\n",
       " 'in',\n",
       " 'and',\n",
       " 'out',\n",
       " 'please',\n",
       " 'pause',\n",
       " 'n1',\n",
       " 'okay',\n",
       " 'd1',\n",
       " 'okay',\n",
       " 'n1',\n",
       " 'those',\n",
       " 'obs',\n",
       " 'pr1',\n",
       " 'there',\n",
       " 'still',\n",
       " 'so',\n",
       " 'we',\n",
       " 'have',\n",
       " 'a',\n",
       " 'heart',\n",
       " 'rate',\n",
       " 'one',\n",
       " 'twenty-eight',\n",
       " 'sats',\n",
       " 'of',\n",
       " 'going',\n",
       " 'between',\n",
       " 'ninety-three',\n",
       " 'and',\n",
       " 'ninety-five',\n",
       " 'and',\n",
       " 'a',\n",
       " 'blood',\n",
       " 'pressure',\n",
       " 'of',\n",
       " 'one',\n",
       " 'eleven',\n",
       " 'eighty-one',\n",
       " 'd1',\n",
       " 'okay',\n",
       " 'n1',\n",
       " 'yeah',\n",
       " 'd1',\n",
       " 'eh',\n",
       " 'i',\n",
       " 'might',\n",
       " 'get',\n",
       " 'a',\n",
       " 'twelve',\n",
       " 'ecg',\n",
       " 'if',\n",
       " 'you',\n",
       " 'don',\n",
       " 't',\n",
       " 'mind',\n",
       " 'n1',\n",
       " 'twelve',\n",
       " 'ecg',\n",
       " 'd1',\n",
       " 'is',\n",
       " 'there',\n",
       " 'an',\n",
       " 'ecg',\n",
       " 'machine',\n",
       " 'here',\n",
       " 'n1',\n",
       " 'there',\n",
       " 'is',\n",
       " 'indeed',\n",
       " 'i',\n",
       " 'll',\n",
       " 'get',\n",
       " 'that',\n",
       " 'for',\n",
       " 'you',\n",
       " 'now',\n",
       " 'd1',\n",
       " 'okay',\n",
       " 'n1',\n",
       " 'temperature',\n",
       " 'i',\n",
       " 'just',\n",
       " 'checked',\n",
       " 'there',\n",
       " 'a',\n",
       " 'moment',\n",
       " 'ago',\n",
       " 'was',\n",
       " 'thirty-eight',\n",
       " 'two',\n",
       " 'd1',\n",
       " 'okay',\n",
       " 'n1',\n",
       " 'which',\n",
       " 'is',\n",
       " 'eh',\n",
       " 'eh',\n",
       " 'a',\n",
       " 'spike',\n",
       " 'now',\n",
       " 'just',\n",
       " 'this',\n",
       " 'morning',\n",
       " 'd1',\n",
       " 'okay',\n",
       " 'i',\n",
       " 'might',\n",
       " 'eh',\n",
       " 'take',\n",
       " 'some',\n",
       " 'bloods',\n",
       " 'as',\n",
       " 'well',\n",
       " 'just…',\n",
       " 'n1',\n",
       " 'sure.',\n",
       " 'okay',\n",
       " 'i',\n",
       " 'll',\n",
       " 'get',\n",
       " 'that',\n",
       " 'ecg',\n",
       " 'd1',\n",
       " 'when',\n",
       " 'did',\n",
       " 'you',\n",
       " 'have',\n",
       " 'the',\n",
       " 'operation',\n",
       " 'mrs',\n",
       " 'o',\n",
       " 'shaughnessy',\n",
       " 'p1',\n",
       " 'oh',\n",
       " 'it',\n",
       " 'was',\n",
       " 'a',\n",
       " 'few',\n",
       " 'days',\n",
       " 'ago',\n",
       " 'd1',\n",
       " 'okay',\n",
       " 'p1',\n",
       " 'three',\n",
       " 'days',\n",
       " 'ago',\n",
       " 'd1',\n",
       " 'and',\n",
       " 'was',\n",
       " 'it',\n",
       " 'on',\n",
       " 'the',\n",
       " 'tummy',\n",
       " 'p1',\n",
       " 'yeah',\n",
       " 'something',\n",
       " 'something',\n",
       " 'in',\n",
       " 'my',\n",
       " 'tummy',\n",
       " 'like',\n",
       " 'sort',\n",
       " 'of',\n",
       " 'a',\n",
       " 'tumour',\n",
       " 'in',\n",
       " 'my',\n",
       " 'tummy',\n",
       " 'i',\n",
       " 'think',\n",
       " 'd1',\n",
       " 'alright',\n",
       " 'okay',\n",
       " 'well',\n",
       " 'i',\n",
       " 'just',\n",
       " 'want',\n",
       " 'to',\n",
       " 'get',\n",
       " 'a',\n",
       " 'tracing',\n",
       " 'of',\n",
       " 'the',\n",
       " 'heart',\n",
       " 'and',\n",
       " 'then',\n",
       " 'i',\n",
       " 'might',\n",
       " 'eh',\n",
       " 'examine',\n",
       " 'the',\n",
       " 'tummy',\n",
       " 'if',\n",
       " 'that',\n",
       " 's',\n",
       " 'okay',\n",
       " 'with',\n",
       " 'you.',\n",
       " 'p1',\n",
       " 'did',\n",
       " 'everything',\n",
       " 'go',\n",
       " 'okay',\n",
       " 'd1',\n",
       " 'eh',\n",
       " 'your',\n",
       " 'heart',\n",
       " 'is',\n",
       " 'going',\n",
       " 'a',\n",
       " 'little',\n",
       " 'bit',\n",
       " 'fast',\n",
       " 'so',\n",
       " 'we',\n",
       " 'just',\n",
       " 'want',\n",
       " 'to',\n",
       " 'check',\n",
       " 'that',\n",
       " 'out',\n",
       " 'further',\n",
       " 'and',\n",
       " 'i',\n",
       " 'm',\n",
       " 'going',\n",
       " 'to',\n",
       " 'take',\n",
       " 'some',\n",
       " 'bloods',\n",
       " 'as',\n",
       " 'well',\n",
       " 'okay',\n",
       " 'p1',\n",
       " 'so',\n",
       " 'is',\n",
       " 'that',\n",
       " 'okay',\n",
       " 'n1',\n",
       " 'just',\n",
       " 'nice',\n",
       " 'and',\n",
       " 'still',\n",
       " 'there',\n",
       " 'for',\n",
       " 'a',\n",
       " 'moment',\n",
       " 'mrs',\n",
       " 'o',\n",
       " 'shaughnessy',\n",
       " 'p1',\n",
       " 'just',\n",
       " 'feel',\n",
       " 'a',\n",
       " 'bit',\n",
       " 'warm',\n",
       " 'n1',\n",
       " 'yeah',\n",
       " 'i',\n",
       " 'll',\n",
       " 'just',\n",
       " 'get',\n",
       " 'you',\n",
       " 'to',\n",
       " 'stay',\n",
       " 'quiet',\n",
       " 'for',\n",
       " 'one',\n",
       " 'second',\n",
       " 'now',\n",
       " 'we',\n",
       " 'll',\n",
       " 'just',\n",
       " 'read',\n",
       " 'that',\n",
       " 'ecg',\n",
       " 'okay',\n",
       " 'great',\n",
       " 'that',\n",
       " 's',\n",
       " 'brilliant',\n",
       " 'there',\n",
       " 'you',\n",
       " 'go',\n",
       " 'd1',\n",
       " 'thank',\n",
       " 'you',\n",
       " 'very',\n",
       " 'much',\n",
       " 'p1',\n",
       " 'what',\n",
       " 's',\n",
       " 'going',\n",
       " 'on',\n",
       " 'd1',\n",
       " 'i',\n",
       " 'd',\n",
       " 'like',\n",
       " 'to',\n",
       " 'get',\n",
       " 'a',\n",
       " 'full',\n",
       " 'blood',\n",
       " 'count',\n",
       " 'smac',\n",
       " 'twenty',\n",
       " 'cop',\n",
       " 'and',\n",
       " 'blood',\n",
       " 'cultures',\n",
       " 'pr2',\n",
       " 'please',\n",
       " 'n1',\n",
       " 'okay',\n",
       " 'd1',\n",
       " 'and',\n",
       " 'a',\n",
       " 'coag',\n",
       " 'as',\n",
       " 'well',\n",
       " 'n1',\n",
       " 'coag',\n",
       " 'as',\n",
       " 'well',\n",
       " 'i',\n",
       " 'see',\n",
       " 'one',\n",
       " 'of',\n",
       " 'your',\n",
       " 'colleagues',\n",
       " 'on',\n",
       " 'the',\n",
       " 'corridor',\n",
       " 'there',\n",
       " 'i',\n",
       " 'might',\n",
       " 'ask',\n",
       " 'him',\n",
       " 'to',\n",
       " 'pop',\n",
       " 'in',\n",
       " 'to',\n",
       " 'you',\n",
       " 'd1',\n",
       " 'yeah',\n",
       " 'would',\n",
       " 'you',\n",
       " 'mind',\n",
       " 'yeah',\n",
       " 'how',\n",
       " 'old',\n",
       " 'are',\n",
       " 'you',\n",
       " 'mrs',\n",
       " 'o',\n",
       " 'shaughnessy',\n",
       " 'p1',\n",
       " 'i',\n",
       " 'am',\n",
       " 'sixty-eight',\n",
       " 'd1',\n",
       " 'sixty-eight',\n",
       " 'p1',\n",
       " 'years',\n",
       " 'young',\n",
       " 'pause',\n",
       " 'is',\n",
       " 'everything',\n",
       " 'going',\n",
       " 'alright',\n",
       " 'i',\n",
       " 'feel',\n",
       " 'a',\n",
       " 'bit',\n",
       " 'weird',\n",
       " 'n1',\n",
       " 'to',\n",
       " 'doctor',\n",
       " 'd2',\n",
       " 'hi',\n",
       " 'pr3',\n",
       " 'doctor',\n",
       " 'd2',\n",
       " 'how',\n",
       " 'are',\n",
       " 'you',\n",
       " 'inaudible',\n",
       " 'pr4',\n",
       " 'd1',\n",
       " 'hiya',\n",
       " 'd2',\n",
       " 'd2',\n",
       " 'hello',\n",
       " 'd1',\n",
       " 'this',\n",
       " 'is',\n",
       " 'mrs',\n",
       " 'o',\n",
       " 'shaughnessy',\n",
       " 'she',\n",
       " 's',\n",
       " 'a',\n",
       " 'sixty-eight',\n",
       " 'year',\n",
       " 'old',\n",
       " 'lady',\n",
       " 'she',\n",
       " 's',\n",
       " 'two',\n",
       " 'days',\n",
       " 'post-laparotomy',\n",
       " 'for',\n",
       " 'the',\n",
       " 'resection',\n",
       " 'of',\n",
       " 'a',\n",
       " 'bowel',\n",
       " 'tumour',\n",
       " 'she',\n",
       " 's',\n",
       " 'been',\n",
       " 'complaining',\n",
       " 'today',\n",
       " 'of',\n",
       " 'some',\n",
       " 'palpitations',\n",
       " 'em',\n",
       " 'and',\n",
       " 'problems',\n",
       " 'with',\n",
       " 'her',\n",
       " 'breathing',\n",
       " 'and',\n",
       " 'kind',\n",
       " 'of',\n",
       " 'a',\n",
       " 'funny',\n",
       " 'feeling',\n",
       " 'in',\n",
       " 'her',\n",
       " 'chest',\n",
       " 'eh',\n",
       " 'so',\n",
       " 'if',\n",
       " 'you',\n",
       " 'wouldn',\n",
       " 't',\n",
       " 'mind',\n",
       " 'would',\n",
       " 'you',\n",
       " 'be',\n",
       " 'able',\n",
       " 'to',\n",
       " 'take',\n",
       " 'some',\n",
       " 'bloods',\n",
       " 'until',\n",
       " 'we',\n",
       " 'have',\n",
       " 'a',\n",
       " 'full',\n",
       " 'blood',\n",
       " 'count',\n",
       " 'smac',\n",
       " 'twenty',\n",
       " 'eh',\n",
       " 'cop',\n",
       " 'cultures',\n",
       " 'and',\n",
       " 'coag',\n",
       " 'please',\n",
       " 'd2',\n",
       " 'okay',\n",
       " 'd1',\n",
       " 'her',\n",
       " 'ecg',\n",
       " 'shows',\n",
       " 'eh',\n",
       " 'signs',\n",
       " 'of',\n",
       " 'tachycardia',\n",
       " 'd2',\n",
       " 'okay',\n",
       " 'so',\n",
       " 'blood',\n",
       " 'cultures',\n",
       " 'or',\n",
       " 'd1',\n",
       " 'please',\n",
       " 'if',\n",
       " 'you',\n",
       " 'wouldn',\n",
       " 't',\n",
       " 'mind',\n",
       " 'yeah.',\n",
       " 'd2',\n",
       " 'inaudible',\n",
       " 'pr5',\n",
       " 'bloods',\n",
       " 'd1',\n",
       " 'and',\n",
       " 'would',\n",
       " 'you',\n",
       " 'be',\n",
       " 'able',\n",
       " 'to',\n",
       " 'put',\n",
       " 'in',\n",
       " 'a',\n",
       " 'line',\n",
       " 'as',\n",
       " 'well',\n",
       " 'for',\n",
       " 'some',\n",
       " 'fluids',\n",
       " 'd2',\n",
       " 'okay',\n",
       " 'which',\n",
       " 'which',\n",
       " 'would',\n",
       " 'you',\n",
       " 'rather',\n",
       " 'me',\n",
       " 'do',\n",
       " 'first',\n",
       " 'n1',\n",
       " 'do',\n",
       " 'you',\n",
       " 'know',\n",
       " 'i',\n",
       " 'can',\n",
       " 'i',\n",
       " 'can',\n",
       " 'do',\n",
       " 'the',\n",
       " 'i',\n",
       " 'can',\n",
       " 'do',\n",
       " 'the',\n",
       " 'bloods',\n",
       " 'd1',\n",
       " 'will',\n",
       " 'you',\n",
       " 'do',\n",
       " 'the',\n",
       " 'bloods',\n",
       " 'and',\n",
       " 'you',\n",
       " 'do',\n",
       " 'the',\n",
       " 'the',\n",
       " 'line',\n",
       " 'please',\n",
       " 'd2',\n",
       " 'okay',\n",
       " 'no',\n",
       " 'worries',\n",
       " 'n1',\n",
       " 'okay',\n",
       " 'd1',\n",
       " 'mrs',\n",
       " 'o',\n",
       " 'shaughnessy',\n",
       " 'we',\n",
       " 're',\n",
       " 'going',\n",
       " 'to',\n",
       " 'put',\n",
       " 'a',\n",
       " 'line',\n",
       " 'into',\n",
       " 'the',\n",
       " 'arm',\n",
       " 'for',\n",
       " 'you',\n",
       " 'okay',\n",
       " 'to',\n",
       " 'give',\n",
       " 'you',\n",
       " 'some',\n",
       " 'fluids',\n",
       " 'n1',\n",
       " 'she',\n",
       " 'actually',\n",
       " 'has',\n",
       " 'an',\n",
       " 'access',\n",
       " 'already',\n",
       " 'p1',\n",
       " 'more',\n",
       " 'lines',\n",
       " 'okay',\n",
       " 'okay.',\n",
       " 'd1',\n",
       " 'oh',\n",
       " 'she',\n",
       " 'has',\n",
       " 'access',\n",
       " 'already.',\n",
       " 'n1',\n",
       " 'em',\n",
       " 'i',\n",
       " 'have',\n",
       " 'her',\n",
       " 'just',\n",
       " 'said',\n",
       " 'that',\n",
       " 'to',\n",
       " 'you',\n",
       " 'yeah.',\n",
       " 'p1',\n",
       " 'what',\n",
       " 's',\n",
       " 'going',\n",
       " 'on',\n",
       " 'n1',\n",
       " 'she',\n",
       " 'has',\n",
       " 'access',\n",
       " 'there',\n",
       " 'she',\n",
       " 'also',\n",
       " 'has',\n",
       " 'p1',\n",
       " 'do',\n",
       " 'i',\n",
       " 'have',\n",
       " 'one',\n",
       " 'already',\n",
       " 'n1',\n",
       " 'because',\n",
       " 'she',\n",
       " 's',\n",
       " 'post-op',\n",
       " 'as',\n",
       " 'you',\n",
       " 'can',\n",
       " 'see',\n",
       " 'd1',\n",
       " 'oh',\n",
       " 'yeah',\n",
       " 'n1',\n",
       " 'she',\n",
       " 'has',\n",
       " 'a',\n",
       " 'central',\n",
       " 'line',\n",
       " 'there',\n",
       " 'so',\n",
       " 'd1',\n",
       " 'okay',\n",
       " 'yeah',\n",
       " 'we',\n",
       " 're',\n",
       " 'going',\n",
       " 'to',\n",
       " 'give',\n",
       " 'you',\n",
       " 'some',\n",
       " 'fluids',\n",
       " 'in',\n",
       " 'through',\n",
       " 'the',\n",
       " 'line',\n",
       " 'and',\n",
       " 'eh',\n",
       " 'p1',\n",
       " 'okay',\n",
       " 'd1',\n",
       " 'n1',\n",
       " 'here',\n",
       " 'is',\n",
       " 'going',\n",
       " 'to',\n",
       " 'take',\n",
       " 'some',\n",
       " 'bloods',\n",
       " 'okay',\n",
       " 'p1',\n",
       " 'okay',\n",
       " 'd1',\n",
       " 'and',\n",
       " 'eh',\n",
       " 'if',\n",
       " 'it',\n",
       " 's',\n",
       " 'okay',\n",
       " 'i',\n",
       " 'd',\n",
       " 'like…',\n",
       " 'p1',\n",
       " 'i',\n",
       " 'm',\n",
       " 'finding',\n",
       " 'it',\n",
       " 'hard',\n",
       " 'to',\n",
       " 'breathe.',\n",
       " 'd1',\n",
       " 'you',\n",
       " 're',\n",
       " 'finding',\n",
       " 'it',\n",
       " 'hard',\n",
       " 'to',\n",
       " 'breathe',\n",
       " 'are',\n",
       " 'you',\n",
       " 'okay',\n",
       " 'we',\n",
       " 'll',\n",
       " 'give',\n",
       " 'you',\n",
       " 'a',\n",
       " 'little',\n",
       " 'bit',\n",
       " 'of',\n",
       " 'oxygen',\n",
       " 'as',\n",
       " 'well',\n",
       " 'and',\n",
       " 'hopefully',\n",
       " 'that',\n",
       " 'll',\n",
       " 'help',\n",
       " 'can',\n",
       " 'i',\n",
       " 'get',\n",
       " 'some',\n",
       " 'eh',\n",
       " 'nasal',\n",
       " 'cannula',\n",
       " 'n1',\n",
       " 'inaudible',\n",
       " 'pr6',\n",
       " 'ask',\n",
       " 'you',\n",
       " 'to',\n",
       " 'maybe',\n",
       " 'deal',\n",
       " 'with',\n",
       " 'that',\n",
       " 'd1',\n",
       " 'yeah',\n",
       " 'no',\n",
       " 'worries',\n",
       " 'n1',\n",
       " 'now',\n",
       " 'd1',\n",
       " 'can',\n",
       " 'i',\n",
       " 'get',\n",
       " 'some',\n",
       " 'nasal',\n",
       " 'cannula',\n",
       " 'just',\n",
       " 'for',\n",
       " 'mrs',\n",
       " 'o',\n",
       " 'shaughnessy',\n",
       " 'she',\n",
       " 's',\n",
       " 'finding',\n",
       " 'it',\n",
       " 'a',\n",
       " 'little',\n",
       " 'bit',\n",
       " 'hard',\n",
       " 'to',\n",
       " 'breathe',\n",
       " 'n1',\n",
       " 'sure.',\n",
       " 'no',\n",
       " 'problem',\n",
       " 'no',\n",
       " 'problem',\n",
       " 'i',\n",
       " 'll',\n",
       " 'just',\n",
       " 'finish',\n",
       " 'these',\n",
       " 'bloods',\n",
       " 'for',\n",
       " 'you',\n",
       " 'and',\n",
       " 'i',\n",
       " 'll',\n",
       " 'get',\n",
       " 'that',\n",
       " 'done',\n",
       " 'd1',\n",
       " 'we',\n",
       " 'might',\n",
       " 'lie',\n",
       " 'her',\n",
       " 'down',\n",
       " 'flat',\n",
       " 'so',\n",
       " 'i',\n",
       " 'can',\n",
       " 'have',\n",
       " 'a',\n",
       " 'look',\n",
       " 'at',\n",
       " 'the',\n",
       " 'n1',\n",
       " 'yeah',\n",
       " 'no',\n",
       " 'problem',\n",
       " 'd1',\n",
       " 'the',\n",
       " 'stomach',\n",
       " 'n1',\n",
       " 'can',\n",
       " 'you',\n",
       " 'manage',\n",
       " 'that',\n",
       " 'd1',\n",
       " 'is',\n",
       " 'it',\n",
       " 'okay',\n",
       " 'if',\n",
       " 'i',\n",
       " 'lie',\n",
       " 'you',\n",
       " 'down',\n",
       " 'flat',\n",
       " 'just',\n",
       " 'so',\n",
       " 'i',\n",
       " 'can',\n",
       " 'have',\n",
       " 'a',\n",
       " 'look',\n",
       " 'at',\n",
       " 'the',\n",
       " 'tummy',\n",
       " 'p1',\n",
       " 'okay',\n",
       " 'n1',\n",
       " 'if',\n",
       " 'you',\n",
       " 'just',\n",
       " 'pull',\n",
       " 'the',\n",
       " 'the',\n",
       " 'little',\n",
       " 'lead',\n",
       " 'on',\n",
       " 'the',\n",
       " 'side',\n",
       " 'there',\n",
       " 'p1',\n",
       " 'is',\n",
       " 'everything',\n",
       " 'okay',\n",
       " 'was',\n",
       " 'the',\n",
       " 'operation',\n",
       " 'okay',\n",
       " 'what',\n",
       " 's',\n",
       " 'going',\n",
       " 'on',\n",
       " 'n1',\n",
       " 'yeah',\n",
       " 'now',\n",
       " 'p1',\n",
       " 'did',\n",
       " 'i',\n",
       " 'fail',\n",
       " 'the',\n",
       " 'blood',\n",
       " 'pr7',\n",
       " 'tests',\n",
       " 'd1',\n",
       " 'we',\n",
       " 're',\n",
       " 'just',\n",
       " 'checking',\n",
       " 'you',\n",
       " 'now',\n",
       " 'mrs',\n",
       " 'o',\n",
       " 'shaughnessy',\n",
       " 'to',\n",
       " 'make',\n",
       " 'sure',\n",
       " 'everything',\n",
       " 's',\n",
       " 'okay',\n",
       " 'n1',\n",
       " 'i',\n",
       " 've',\n",
       " 'those',\n",
       " 'blood',\n",
       " 'tests',\n",
       " 'done',\n",
       " 'there',\n",
       " 'so',\n",
       " 'i',\n",
       " 've',\n",
       " 'peripheral',\n",
       " 'cultures',\n",
       " 'fec',\n",
       " 'pr8',\n",
       " 'smac',\n",
       " 'twenty',\n",
       " 'cop',\n",
       " 'and',\n",
       " 'eh',\n",
       " 'inaudibl',\n",
       " 'pr9',\n",
       " 'e',\n",
       " 'pr10',\n",
       " 'p1',\n",
       " 'i',\n",
       " 'm',\n",
       " 'really',\n",
       " 'finding',\n",
       " 'it',\n",
       " 'hard',\n",
       " 'to',\n",
       " 'breathe',\n",
       " 'd1',\n",
       " 'that',\n",
       " 's',\n",
       " 'great',\n",
       " 'thank',\n",
       " 'you',\n",
       " 'very',\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"tokenize_only\")\n",
    "test = \"Hi my friends\"\n",
    "tokenize_only(test)\n",
    "\n",
    "print(\"open_and_tokenize\")\n",
    "##################  loop over this & increment counter +1 each time.\n",
    "counter = 0\n",
    "folder  = \"sentiment_text_data\"\n",
    "open_and_tokenize(counter, folder)\n",
    "\n",
    "# print(\"tokenize_and_stem\")\n",
    "# tokenize_and_stem(test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create empty lists to contain the results\n",
    "\n",
    "\n",
    "##### Speakers & Turns\n",
    "7. no. of speakers for each dialogue\n",
    "8. no. turns per speaker\n",
    "9. no. words per speaker\n",
    "14. mean no. words per turn\n",
    "15. total turns per dialogue\n",
    "16. total words per dialogue\n",
    "17. Perc. total turns uttered by each speaker\n",
    "18. Perc. total words uttered by each speaker\n",
    "26. mean sentence length per speaker (do Men use shorter sentences? some research suggests this?)\n",
    "\n",
    "##### Positive & Negative Sentiment\n",
    "1. set of all positive words \n",
    "2. set of all negative words\n",
    "3. frequency of pos words (i.e. frequency distribution)\n",
    "4. frequency of neg words (i.e. frequency distribution)\n",
    "5. pos score for each dialogue\n",
    "6. neg score for each dialogue\n",
    "10. Perc. words that are positive\n",
    "11. Perc. words that are negative\n",
    "21. Positive word per speaker\n",
    "22. Negative word per speaker\n",
    "\n",
    "##### Active & Passive phrases\n",
    "12. Perc. words that are active\n",
    "13. Perc. words that are passive\n",
    "19. ACtive word per speaker\n",
    "20. Passive word per speaker\n",
    "\n",
    "##### Parts of Speech\n",
    "23. adverbs per speaker (e.g. Women elaborate more than men - women use adverbs more)\n",
    "24. adjectives per speaker\n",
    "25. freq of word \"I\" per speaker.\n",
    "\n",
    "##### Medical terms\n",
    "27. count medical terminology / concepts / jargon per speaker\n",
    "\n",
    "##### Alignment / repetition / mirroring\n",
    "28. mirroring of communication style (e.g. gender effects)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run -i sentiment_create_scores.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### show some of these empty lists that i created:\n",
    "\n",
    "positive_score_list\n",
    "pos_set_all_dialogue\n",
    "Num_turns_P1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check number of files present in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check how many files in the directory\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(\"Check how many files in the directory\")\n",
    "### Check how many files in the directory\n",
    "no_files = len(os.listdir(folder))\n",
    "no_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Loop (i.e. repeat for every text file in folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Specific words: occurrence count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File number: 1\n",
      "File name: 1_1 PR.txt\n",
      "\n",
      "Open file and display 'type'\n",
      "\n",
      "Read file and display 'type'\n",
      "\n",
      "Tokenise file and display 'type'\n",
      "\n",
      "Just show the first & last 10 words of the main dialogue text file\n",
      "These are first 10 words:\n",
      "scenario\n",
      "pos\n",
      "aaa\n",
      "d1\n",
      "it\n",
      "s\n",
      "going\n",
      "a\n",
      "little\n",
      "bit\n",
      "These are last 10 words:\n",
      "pr43\n",
      "pr44\n",
      "pr45\n",
      "pr46\n",
      "pr47\n",
      "pr48\n",
      "pr49\n",
      "pr50\n",
      "pr51\n",
      "1_1.mp3\n",
      "word_i_count\n",
      "110\n",
      "\n",
      "word_you_count\n",
      "137\n",
      "\n",
      "word_we_count\n",
      "45\n",
      "\n",
      "word_decide_count\n",
      "0\n",
      "\n",
      "word_decision_count\n",
      "0\n",
      "\n",
      "word_option_count\n",
      "1\n",
      "\n",
      "word_options_count\n",
      "0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokens = open_and_tokenize(counter, folder)\n",
    "doc = nlp(str(tokens))\n",
    "\n",
    "\n",
    "\n",
    "### \"list_words\" --- user input from the beginning\n",
    "\n",
    "dictionary_word_count = {} \n",
    "\n",
    "for x in  list_words:\n",
    "        dictionary_word_count[\"word_{0}_count\".format(x)] = 0\n",
    "\n",
    "\n",
    "for word in doc:\n",
    "    for x in  list_words:\n",
    "        if str(word) == x:\n",
    "            dictionary_word_count[\"word_{0}_count\".format(x)] += 1\n",
    "\n",
    "for x in  list_words:\n",
    "    print(\"word_{0}_count\".format(x))\n",
    "    print(dictionary_word_count[\"word_{0}_count\".format(x)])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File number: 1\n",
      "File name: 1_1 PR.txt\n",
      "\n",
      "Open file and display 'type'\n",
      "\n",
      "Read file and display 'type'\n",
      "\n",
      "Tokenise file and display 'type'\n",
      "\n",
      "Just show the first & last 10 words of the main dialogue text file\n",
      "These are first 10 words:\n",
      "scenario\n",
      "pos\n",
      "aaa\n",
      "d1\n",
      "it\n",
      "s\n",
      "going\n",
      "a\n",
      "little\n",
      "bit\n",
      "These are last 10 words:\n",
      "pr43\n",
      "pr44\n",
      "pr45\n",
      "pr46\n",
      "pr47\n",
      "pr48\n",
      "pr49\n",
      "pr50\n",
      "pr51\n",
      "1_1.mp3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"'the\",\n",
       " 'that',\n",
       " 'you',\n",
       " 'that',\n",
       " \"when', 'did', 'you', 'have', 'the', 'operation', 'mrs', 'o', 'shaughnessy', 'p1', 'oh', 'it',\",\n",
       " \"'p1', 'three', 'days', 'ago', 'd1', 'and'\",\n",
       " \"'in', 'my', 'tummy', 'i', 'think', 'd1', 'alright', 'okay', 'well', 'i', 'just', 'want', 'to', 'get', 'a', 'tracing', 'of', 'the', 'heart', 'and', 'then', 'i', 'might', 'eh', 'examine', 'the', 'tummy', 'if', 'that', 's', 'okay', 'with', 'you.', 'p1', 'did', 'everything', 'go',\",\n",
       " \"'okay', 'd1', 'eh', '\",\n",
       " \"your', 'heart', '\",\n",
       " \"'i', 'm',\",\n",
       " \"'mrs', 'o', 'shaughnessy', 'p1', 'just', '\",\n",
       " \"'s', 'going', 'on', 'd1', 'i', 'd', 'like', 'to',\",\n",
       " \"'okay', 'd1', 'and', 'a', 'coag', 'as', 'well', 'n1', 'coag', 'as', 'well', 'i', 'see', 'one', 'of', 'your', 'colleagues', 'on', 'the', 'corridor', 'there', 'i', 'might', 'ask', 'him', 'to', 'pop', 'in', 'to', 'you', 'd1', 'yeah', 'would', 'you', 'mind', 'yeah', 'how', 'old',\",\n",
       " \"'i'\",\n",
       " \", 'doctor', 'd2', 'hi', 'pr3', 'doctor', 'd2', 'how', 'are', 'you', 'inaudible', 'pr4', 'd1', 'hiya', 'd2', 'd2', 'hello', 'd1', 'this',\",\n",
       " \"'mrs', 'o\",\n",
       " 'she',\n",
       " \"'her\",\n",
       " 'you',\n",
       " 'some',\n",
       " \"'i',\",\n",
       " \"'no\",\n",
       " 'that',\n",
       " 'you',\n",
       " \"she'\",\n",
       " \"'see', 'd1', 'oh', 'yeah', 'n1', 'she',\",\n",
       " 'we',\n",
       " 'it',\n",
       " \", 'd1', 'you', 're', 'finding', 'it', 'hard', 'to', 'breathe',\",\n",
       " \"'i'\",\n",
       " \"', 'the', 'little', 'lead', 'on', 'the', 'side', 'there', 'p1', '\",\n",
       " \", 'd1', 'we', 're', 'just', 'checking', 'you', 'now', 'mrs', 'o', 'shaughnessy', 'to', 'make', 'sure', 'everything', 's', 'okay', 'n1', 'i', 've', 'those', 'blood', 'tests', 'done', 'there', 'so', 'i', 've', 'peripheral', 'cultures', 'fec', 'pr8', 'smac', 'twenty', 'cop', 'and', 'eh', 'inaudibl', 'pr9', 'e', 'pr10', 'p1', 'i', 'm', 'really', 'finding', 'it', 'hard', 'to', 'breathe', 'd1', 'that', 's', 'great', 'thank', 'you', 'very', 'much', 'we', 're', 'going', 'to', 'get', 'you', 'a', 'little', 'bit', 'of', 'oxygen', 'now', 'and', 'that', 'should', 'help', 'with', 'the', 'the', 'feeling', 'of', 'shortness', 'of', 'breath', 'okay', 'pause', 'p1', 'oh', 'it', 's', 'really', 'it', 's', 'getting', 'worse', 'to', 'breathe', 'now', 'that', 'i', 'm', 'lying', 'down', 'd1', 'is', 'it', 'p1', 'it', 'really', 'hurts', 'when', 'i', 'breathe', 'in', 'd1', 'okay', 'em', 'n1', 'inaudible', 'pr11', 'stick', 'on', 'a', 'mask', 'd1', 'do', 'you', 'n1',\",\n",
       " \"it', 'hard', 'to', 'breathe', 'd1', '\",\n",
       " \"it', 'hard', 'to', 'breathe', 'd1', 'that\",\n",
       " 'i',\n",
       " \"'s', 'fine', 'n1',\",\n",
       " 'she',\n",
       " \"she'\",\n",
       " 'they',\n",
       " \"'we'\",\n",
       " \"you'\",\n",
       " \", 'uhh', 'd1', 'i', 'm', '\",\n",
       " \"'d1', 'and', 'i', 'want', 'you', 'to',\",\n",
       " \"', 'temperature', 's', 'still', 'inaudible', 'pr12', 'there', 'd1', 'okay', 'how', 's', 'that',\",\n",
       " 'you',\n",
       " 'it',\n",
       " \", 'd1', 'eh', 'so',\",\n",
       " \"'r1',\",\n",
       " 'you',\n",
       " \"', 'em', 'the', 'this', 'lady', 'already'\",\n",
       " \", 'a', 'peripheral', 'line', 'and', 'd1', 'okay', 'd2', '\",\n",
       " 'you',\n",
       " 'you',\n",
       " \"'i', 'grab', 'a', 'pair', 'of', 'gloves', 'as', 'well', 'please', 'n1', 'yeah', 'they', 're', 'just', 'around', 'the', 'other', 'side', 'of', 'the', 'bed', 'there', 'd2', 'pair', 'of', 'gloves', 'd1', 'yeah', 'p1',\",\n",
       " \"'i', 'm',\",\n",
       " \"'an', 'abg', 'pr14', 'done', 'p1',\",\n",
       " 'i',\n",
       " \"'yeah', 'd1', 'sorry', 'mrs', 'o\",\n",
       " 'she',\n",
       " \", 'the', 'wound', 'd1', 'inaudible', 'pr18', 'leak', 'maybe', 'from', 'the', 'the', 'bowel', 'surgery', 'n1', 'in', 'the', 'tummy', 'oh', 'really', 'd1', 'in', 'the', 'tummy', 'yeah', 'n1', 'okay', 'okay', 'd1', 'yeah', 'p1', 'is', 'something', 'going', 'on', 'with', 'with', 'the', 'surgery', 'd1', 'i', 'm', 'not', 'a', 'hundred', 'per', 'cent', 'sure', 'yet', 'mrs', 'o', 'shaughnessy', 'but', 'i', 'm', 'going', 'to', 'check', 'now', 'and', 'i', 'm', 'going', 'to', 'try', 'my', 'best', 'to', 'find', 'out', 'we', 've', 'sent', 'some', 'bloods', 'and', 'we', 're', 'just', 'waiting', 'on', 'the', 'results', 'of', 'those', 'p1', 'it', 'hurts', 'a', 'bit', 'when', 'i', 'breathe', 'in', 'd2', 'd1', 'em', 'portable', 'chest', 'x-ray',\",\n",
       " \"'some\",\n",
       " 'we',\n",
       " \"it'\",\n",
       " 'i',\n",
       " \", 'order', 'an', 'assistant', 'd2', 'okay', 'n1'\",\n",
       " 'the',\n",
       " \"'the', 'surgery',\",\n",
       " \"'the', 'surgery',\",\n",
       " \"'i', 'm', 'just', 'down', 'here', 'on', 'the', 'post-op', 'surgical', 'ward', 'i', 'wonder', 'could', 'i', 'request', 'a', 'portable', 'chest', 'x-ray', 'for', 'mrs', 'o', 'shaughnessy', 'inaudible', 'pr20', 'p1', 'ow.', 'n1', 'thank', 'you', 'd1', 'that', 's', 'sore', 'there', 'is', 'it', 'p1', 'a', 'little', 'bit.', 'n1', 'that', 'chest', 'x-ray', 's', 'ordered', 'em', 'blood', 'pressure', 's', 'not', 'great', 'she', 's', 'still', 'not', 'great.', 'd1', 'yeah', 'no.', 'n1'\",\n",
       " 'there',\n",
       " 'she',\n",
       " 'i',\n",
       " \"'we'\",\n",
       " \"'d1', 'her', 'tummy'\",\n",
       " 'it',\n",
       " \"'d1', 'thinking', 'it',\",\n",
       " \"'i'\",\n",
       " 'we',\n",
       " \"'what',\",\n",
       " 'it',\n",
       " '…',\n",
       " \"there', 'mrs', 'o', 'shaughnessy', 'p1', 'oh',\",\n",
       " \"'i',\",\n",
       " \"'there', 'so', 'your', 'heart', 'the', 'heart', 'rate', 'there', 'one', 'thirty-four', 'sats', '\",\n",
       " \"'they'\",\n",
       " 'you',\n",
       " 'that',\n",
       " 'she',\n",
       " 'you',\n",
       " 'you',\n",
       " 'there',\n",
       " \"'d2'\",\n",
       " 'you',\n",
       " \"'hear', 'me', 'mrs', 'o', 'shaughnessy', 'p1', 'eh', 'd1', 'okay', 'inaudible', 'pr30', 'n1', 'you', 'can', 'okay.', 'alright', 'i', 'll', 'just', 'get', 'this', 'oxygen', 'on', 'd2', 'so', 'is', 'the', 'airway', 'okay', 'n1', 'yeah', 'r1', 'okay', 'responding', 'okay', 'n1', 'she', 's', 'just', 'responded', 'to', 'me', 'there', 'yeah', 'yeah', 'd1', 'inaudible', 'pr31', 'n1', 'you', 're', 'getting', 'an', 'abg', 'there', 'd2', 'yeah', 'n1', 'is', 'it', 'okay', 'great', 'alright', 'mrs', 'o', 'shaughnessy', 'we', 're', 'just', 'getting', 'you', 'organised', 'p1', 'eh', 'n1', 'set', 'd2', 'i', 'm', 'i', 'm',\",\n",
       " \"', 'getting', 'a', 'venous', 'blood', 'sample', 'n1', 'okay', 'okay', 'd2',\",\n",
       " \"'i'\",\n",
       " 'they',\n",
       " 'you',\n",
       " 'you',\n",
       " 'there',\n",
       " \"'it',\",\n",
       " \"the', 'senior', 'doctors'\",\n",
       " 'that',\n",
       " 'you',\n",
       " \", 'need', 'another', 'fluid', 'bolus', 'inaudible', 'pr39', 'd1', 'yeah', 'so', '\",\n",
       " 'it',\n",
       " \"'d1', 'yeah', 'can', 'you', 'chart', 'that', 'd2', 'yeah', 'd2', 'perfect', 'd1', 'em', 'and', 'so', 'i', 'can', 'do', 'the', 'inaudible', 'pr40', 'd2',\",\n",
       " \"that', 'inaudible', 'pr42', 'd1', 'inaudible', 'pr43', 'f3', 'perfect', 'and', 'had', 'she', 'been', 'on', 'antibiotics', 'already', 'd1', 'eh', 'i',\",\n",
       " 'she',\n",
       " 'that',\n",
       " \"'we'\",\n",
       " 'she',\n",
       " \"', 'yeah', 'n1',\",\n",
       " 'she',\n",
       " 'that',\n",
       " \"'we', 'should'\",\n",
       " \"'i',\",\n",
       " 'it',\n",
       " \"'d1', 'sorry', 'r1', 'her', 'urine', 'output', 'd2', 'em', 'so', 'd1', 'just', 'regards', 'the', 'urine', 'output',\",\n",
       " 'we',\n",
       " 'she',\n",
       " 'she',\n",
       " \", 'mrs', 'o', 'shaughnessy', 'n1', 'she', 'had', 'the', 'catheter', 'in', 'alright', 'yeah', 'you', 're', 'wondering', 'about', 'urine', 'output', 'p1', 'eh', 'n1', 'yeah', 'just', 'about', 'thirty', 'mils', 'in', 'd1', 'okay.', 'n1', 'the', 'last', 'four', 'hours', 'actually', 'd1', 'okay', 'n1', 'yeah', 'd1', 'she', 's', 'not', 'eh', 'she', 's', 'not', 'really', 'responsive', 'n1', 'yeah', 'd1', 'em', 'n1', 'that', 's', 'anaesthetics', 'there', 'now', 'd1', 'd2', 'can', 'you', 'inaudible', 'pr48', 'd2', 'yeah', 'okay', 'n1', 'have', 'you', 'do', 'you', 'want', 'me', 'to', 'run', 'with', 'the', 'avg', 'd2', 'em', 'yeah',\",\n",
       " \"'s', 'anaesthetics', 'there', 'now', 'd1', 'd2', 'can', 'you', 'inaudible', 'pr48', 'd2', 'yeah', 'okay', 'n1', 'have', 'you', 'do', 'you',\",\n",
       " \"there', 'now', 'd1', 'd2', 'can', 'you', 'inaudible', 'pr48', 'd2', 'yeah', 'okay', 'n1'\",\n",
       " \"', 'd1', 'd2',\",\n",
       " \"you'\",\n",
       " 'you',\n",
       " \"'the', 'urine', 'output', '\",\n",
       " \"', 're-reassess', 'we',\",\n",
       " \"'two', 'fluid', 'boluses', 'f3', 'okay', 'd2', 'em', 'f3', 'and', 'her', 'blood', 'pressure', '\",\n",
       " 'she',\n",
       " \"'very', 'much', 'n1',\",\n",
       " 'the',\n",
       " \"'so', 'patient', '\",\n",
       " \"'the', 'abg', 'r1', 'yeah', 'lactase', 'four', 'point', 'five', 'd1', 'okay', 'd2',\",\n",
       " 'we',\n",
       " 'we',\n",
       " 'we',\n",
       " \"'the', 'result', 'of', 'her', 'avg', 'there', 'her', 'lactase',\",\n",
       " 'she',\n",
       " \"she'\"]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'adjective_count': 0,\n",
       " 'adjective_list': '',\n",
       " 'adverb_count': 0,\n",
       " 'adverb_list': '',\n",
       " 'personal_pronoun_count': 0,\n",
       " 'personal_pronoun_list': '',\n",
       " 'verb_count': 0,\n",
       " 'verb_list': ''}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verb_count\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "verb_list\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"'just', 'checked', 'there',\",\n",
       " \"that', 'for', 'you', 'now', 'd1', 'okay', 'n1', 'temperature', 'i', 'just', 'checked', 'there', 'a', 'moment', 'ago', 'was', 'thirty-eight', 'two', 'd1', 'okay', 'n1', 'which', 'is', 'eh', 'eh', 'a', 'spike', 'now', 'just', 'this', 'morning'\",\n",
       " \"when', 'did', 'you',\",\n",
       " \"when', 'did', 'you', 'have', 'the', 'operation', 'mrs', 'o', 'shaughnessy', 'p1', 'oh', 'it', 'was', 'a', 'few', 'days', 'ago'\",\n",
       " \"'p1', 'three', 'days', 'ago', 'd1', 'and', 'was', 'it', 'on', 'the', 'tummy', 'p1', 'yeah', 'something', 'something', 'in', 'my', 'tummy', 'like', 'sort', 'of', 'a', 'tumour', 'in', 'my', 'tummy', 'i', 'think', 'd1', 'alright', 'okay', 'well', 'i', 'just', 'want', 'to', 'get', 'a', 'tracing', 'of', 'the', 'heart', 'and', 'then', 'i', 'might', 'eh', 'examine', 'the', 'tummy', 'if', 'that', 's', 'okay', 'with', 'you.', 'p1', 'did', 'everything', 'go', 'okay', 'd1', 'eh', 'your', 'heart', 'is', 'going', 'a', 'little', 'bit', 'fast', 'so', 'we', 'just', 'want', 'to', 'check', 'that', 'out', 'further', 'and', 'i', 'm', 'going', 'to', 'take', 'some', 'bloods', 'as', 'well', 'okay', 'p1', 'so', 'is', 'that', 'okay', 'n1', 'just', 'nice', 'and', 'still', 'there', 'for', 'a', 'moment', 'mrs', 'o', 'shaughnessy', 'p1', 'just', 'feel', 'a', 'bit', 'warm', 'n1', 'yeah', 'i', 'll', 'just', 'get', 'you', 'to', 'stay', 'quiet', 'for', 'one', 'second', 'now', 'we', 'll', 'just', 'read', 'that', 'ecg', 'okay', 'great', 'that', 's', 'brilliant', 'there', 'you', 'go', 'd1', 'thank', 'you', 'very', 'much', 'p1', 'what', 's', 'going', 'on', 'd1', 'i', 'd', 'like', 'to', 'get', 'a', 'full', 'blood', 'count', 'smac', 'twenty', 'cop', 'and', 'blood', 'cultures', 'pr2', 'please', 'n1', 'okay', 'd1', 'and', 'a', 'coag', 'as', 'well', 'n1', 'coag', 'as', 'well', 'i', 'see', 'one', 'of', 'your', 'colleagues', 'on', 'the', 'corridor', 'there', 'i', 'might', 'ask', 'him', 'to', 'pop', 'in', 'to', 'you', 'd1', 'yeah', 'would', 'you', 'mind', 'yeah', 'how', 'old', 'are', 'you', 'mrs', 'o', 'shaughnessy', 'p1', 'i', 'am', 'sixty-eight', 'd1', 'sixty-eight', 'p1', 'years', 'young', 'pause', 'is', 'everything', 'going', 'alright',\",\n",
       " \"'did', 'everything', 'go',\",\n",
       " \"'i', 'can', 'i', 'can', 'do', 'the', 'i', 'can', 'do', 'the', 'bloods', 'd1', 'will', 'you', 'do', 'the', 'bloods', 'and', 'you', 'do', 'the', 'the', 'line', 'please', 'd2', 'okay', 'no', 'worries', 'n1', 'okay', 'd1', 'mrs', 'o', 'shaughnessy', 'we', 're', 'going', 'to', 'put', 'a', 'line', 'into', 'the', 'arm', 'for', 'you', 'okay', 'to', 'give', 'you', 'some', 'fluids', 'n1', 'she', 'actually', 'has', 'an', 'access', 'already', 'p1', 'more', 'lines', 'okay', 'okay.', 'd1', 'oh', 'she', 'has', 'access', 'already.', 'n1', 'em', 'i', 'have', 'her', 'just', 'said', 'that', 'to', 'you', 'yeah.', 'p1', 'what', 's', 'going', 'on', 'n1', 'she', 'has', 'access', 'there', 'she', 'also', 'has', 'p1', 'do', 'i', 'have', 'one', 'already', 'n1', 'because', 'she', 's', 'post-op', 'as', 'you', 'can',\",\n",
       " \"'okay', 'was', 'the', 'operation', 'okay', 'what', 's', 'going', 'on', 'n1', 'yeah', 'now', 'p1', 'did', 'i', 'fail', 'the', 'blood', 'pr7', 'tests'\",\n",
       " \"'did'\",\n",
       " \"'she', 'got', 'the', 'fluids', 'going', 'n1', 'and', 'saturated', 'she', 'does', 'she', 'has', 'fluids', 'going', 'in', 'since', 'eh', 'post-op', 'they', 're', 'they', 're', 'just', 'going', 'over', 'twenty-four', 'hours', 'would', 'you', 'like…', 'd1',\",\n",
       " \"saturated'\",\n",
       " \"wanted'\",\n",
       " \", 'mentioned', '\",\n",
       " \"'i', 'grab', 'a', 'pair', 'of', 'gloves', 'as', 'well', 'please', 'n1', 'yeah', 'they', 're', 'just', 'around', 'the', 'other', 'side', 'of', 'the', 'bed', 'there', 'd2', 'pair', 'of', 'gloves', 'd1', 'yeah', 'p1', 'did', 'something', 'go', 'wrong', 'with', 'the', 'surgery', 'what', 's', 'going', 'on', 'd1', 'i', 'm', 'just', 'checking', 'the', 'wound', 'now', 'to', 'make', 'sure', 'everything', 's', 'okay', 'p1', 'is', 'everything', 'okay', 'did', 'everything', 'go', 'okay', 'd1', 'the', 'sur…', 'p1', 'am', 'i', 'having', 'a', 'heart', 'attack', 'd1', 'no', 'you', 're', 'not\",\n",
       " \"'did'\",\n",
       " \", 'sent',\",\n",
       " \"'p1', 'okay.', 'just', 'where', 'the', 'where', 'the', 'surgery', 'was', 'd1', 'just', 'where', 'the', 'surgery', 'was', 'p1', 'it', 's', 'a', 'bit', 'sore', 'n1', 'hi',\",\n",
       " \"where', 'the', 'surgery', 'was', 'p1', 'it',\",\n",
       " \"ordered', 'em',\",\n",
       " \"'getting', 'you', 'sorted', 'out', 'now', 'okay', 'we', 'll', 'get', 'you', 'comfortable'\",\n",
       " \"'p1', 'did', 'something', 'go', 'wrong', 'with', 'the', 'surgery', 'n1', 'no', 'problem', 'd2', 'inaudible', 'pr24', 'n1', 'the', 'doctors', 'are', 'just', 'checking', 'that', 'out', 'now', 'mrs', 'o', 'shaughnessy', 'i'\",\n",
       " \"'was', 'saying', 'there', 'a', 'moment', 'ago'\",\n",
       " \"that', 'sorted', 'out',\",\n",
       " \"'just', 'responded', 'to', 'me', 'there', 'yeah', 'yeah', 'd1', 'inaudible', 'pr31', 'n1', 'you', 're', 'getting', 'an', 'abg', 'there', 'd2', 'yeah', 'n1', 'is', 'it', 'okay', 'great', 'alright', 'mrs', 'o', 'shaughnessy', 'we', 're', 'just', 'getting', 'you', 'organised', 'p1', 'eh', 'n1', 'set', 'd2', '\",\n",
       " \"'what', 's', 'that', 'd2', 'so', 'em', 'em', 'i', 'was', 'chatting', 'to', 'n1', 'there', 'and', 'n1', 'feels', 'that', 'we', 'should', 'be', 'doing', 'an', 'avg', 'if', 'that', 's', 'okay', 'd1', 'okay', 'n1', 'would', 'you',\",\n",
       " \"'left',\",\n",
       " \"', 'had'\",\n",
       " \", 'dropped', 'there', 'again',\",\n",
       " \"'dropped', 'n1', 'eighty-six',\",\n",
       " \"'d1', 'sorry', 'r1', 'her', 'urine', 'output', 'd2', 'em', 'so', 'd1', 'just', 'regards', 'the', 'urine', 'output', 'was', 'it',\",\n",
       " \"had'\",\n",
       " \"'was', 'after', 'the', 'first', 'second', 'bolus', 'was', 'just', 'running', 'out', 'first', 'bolus…', 'd2',\",\n",
       " \"the', 'first', 'second', 'bolus', 'was', 'just', 'running', 'out', 'first', 'bolus…', 'd2',\",\n",
       " \", 'increased'\",\n",
       " \"'started', 'her', 'on', 'antibiotics', 'd2'\",\n",
       " \"the', 'anaesthetic', 'registrar', 'r2', 'hi', 'd1', 'hi', 'yeah', 'sorry', 'this', 'was', 'me', 'so', 'this', 'is', 'pauline', 'r2', 'okay', 'd1', 'o', 'shaughnessy', 'we', 've', 'got', 'the', 'result', 'of', 'her', 'avg', 'there', 'her', 'lactase', 'is', 'four', 'point', 'five', 'r2', 'okay', 'has', 'she', 'got', 'fluids', 'd1', 'em', 'eh', 'she', 's', 'yeah', 'she', 'got', 'two', 'boluses.', 'xxx', 'end', 'of', 'transcript', 'f', 'okay', 'well', 'done', 'guys', 'excellent', 'turn', 'off', 'your', 'mics', 'and', 'go', 'in', 'next', 'door', 'well', 'done', 'pr1', 'referring', 'to', 'the', 'monitor', 'pr2', 'pr3', 'note', 'doctor', 'enters', 'pr4', 'pr5', 'pr6', 'pr7', 'pr8', 'pr9', 'pr10', 'pr11', 'pr12', 'pr13', 'pr14', 'pr15', 'pr16', 'pr17', 'pr18', 'pr19', 'pr20', 'pr21', 'pr22', 'pr23', 'pr24', 'pr25', 'pr26', 'pr27', 'pr28', 'pr29', 'pr30', 'pr31', 'pr32', 'pr33', 'pr34', 'pr35', 'pr36', 'pr37', 'pr38', 'pr39', 'pr40', 'pr41', 'pr42', 'pr43', 'pr44', 'pr45', 'pr46', 'pr47', 'pr48', 'pr49', 'pr50', 'pr51', '1_1.mp3']\",\n",
       " \", 'got'\",\n",
       " \"'she', 'got', 'fluids', 'd1', 'em', 'eh', 'she', 's', 'yeah', 'she', 'got', 'two', 'boluses\",\n",
       " \"she', 'got', 'two', 'boluses\"]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "personal_pronoun_count\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "466"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "personal_pronoun_list\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['it',\n",
       " \"i'\",\n",
       " 'you',\n",
       " \"we', 'll'\",\n",
       " 'you',\n",
       " 'we',\n",
       " \"you'\",\n",
       " 'you',\n",
       " 'it',\n",
       " 'you',\n",
       " \"'we',\",\n",
       " \"'i', 'might'\",\n",
       " 'you',\n",
       " \"'i',\",\n",
       " 'you',\n",
       " \"'i',\",\n",
       " \"'i'\",\n",
       " \"i', 'll'\",\n",
       " 'you',\n",
       " 'it',\n",
       " 'it',\n",
       " \"'i'\",\n",
       " \"'i', 'just'\",\n",
       " \"'i'\",\n",
       " 'you',\n",
       " 'we',\n",
       " \"'i', 'm',\",\n",
       " \"'i', 'll'\",\n",
       " 'you',\n",
       " \"'we'\",\n",
       " \"you'\",\n",
       " 'you',\n",
       " 'i',\n",
       " \"'i'\",\n",
       " 'i',\n",
       " 'him',\n",
       " 'you',\n",
       " \"you'\",\n",
       " 'you',\n",
       " \"'i', 'am', 'sixty-eight', 'd1', 'sixty-eight', 'p1', 'years', 'young', 'pause'\",\n",
       " \"'i'\",\n",
       " 'you',\n",
       " 'she',\n",
       " \"'she'\",\n",
       " \"she', 's'\",\n",
       " 'em',\n",
       " \"'her\",\n",
       " \"'her',\",\n",
       " 'you',\n",
       " \"'you'\",\n",
       " \"'we', 'have', 'a', 'full', 'blood', 'count', 'smac', 'twenty', 'eh', 'cop', 'cultures', 'and', 'coag'\",\n",
       " 'her',\n",
       " 'you',\n",
       " 'you',\n",
       " \"'you', 'rather', 'me'\",\n",
       " \"'me'\",\n",
       " 'you',\n",
       " \"'i',\",\n",
       " \"'i',\",\n",
       " \"'i'\",\n",
       " \"'you'\",\n",
       " 'you',\n",
       " \"we'\",\n",
       " 'you',\n",
       " 'you',\n",
       " 'she',\n",
       " \"she'\",\n",
       " 'em',\n",
       " \"i', 'have', 'her', 'just'\",\n",
       " \"'her', 'just'\",\n",
       " 'you',\n",
       " 'she',\n",
       " \"she'\",\n",
       " \"i'\",\n",
       " 'she',\n",
       " 'you',\n",
       " 'she',\n",
       " 'we',\n",
       " 'you',\n",
       " 'it',\n",
       " \"'i', 'd', 'like…', 'p1', 'i', 'm', 'finding', 'it', 'hard', 'to', 'breathe.'\",\n",
       " \"'i', 'm', 'finding', 'it', 'hard', 'to', 'breathe\",\n",
       " \"'it'\",\n",
       " 'you',\n",
       " \"it', 'hard', 'to', 'breathe',\",\n",
       " 'you',\n",
       " \"we', 'll'\",\n",
       " 'you',\n",
       " \"i'\",\n",
       " 'you',\n",
       " \"'i', 'get', 'some', 'nasal', 'cannula', 'just', 'for', 'mrs', 'o', 'shaughnessy', 'she', 's', 'finding', 'it', 'a', 'little', 'bit', 'hard', 'to', 'breathe', 'n1', 'sure.', 'no', 'problem', 'no', 'problem', 'i', 'll', 'just', 'finish', 'these', 'bloods', 'for', 'you', 'and\",\n",
       " 'she',\n",
       " 'it',\n",
       " \"'i', 'll', 'just', 'finish', 'these', 'bloods', 'for', 'you', 'and\",\n",
       " \"'you', 'and\",\n",
       " \"'i'\",\n",
       " 'we',\n",
       " \"'her', 'down', 'flat'\",\n",
       " \"i'\",\n",
       " 'you',\n",
       " 'it',\n",
       " \"i'\",\n",
       " 'you',\n",
       " \"i'\",\n",
       " 'you',\n",
       " 'i',\n",
       " \"'we',\",\n",
       " 'you',\n",
       " \"'i', 've', 'those', 'blood', 'tests', 'done', 'there', 'so', 'i', 've', 'peripheral', 'cultures', 'fec', 'pr8', 'smac', 'twenty', 'cop', 'and', 'eh', 'inaudibl', 'pr9', 'e', 'pr10', 'p1', 'i', 'm', 'really', 'finding', 'it', 'hard', 'to', 'breathe', 'd1', 'that', 's', 'great', 'thank', 'you', 'very', 'much', 'we', 're', 'going', 'to', 'get', 'you', 'a', 'little', 'bit', 'of', 'oxygen', 'now', 'and', 'that', 'should', 'help', 'with', 'the', 'the', 'feeling', 'of', 'shortness', 'of', 'breath', 'okay', 'pause', 'p1', 'oh', 'it', 's', 'really', 'it', 's', 'getting', 'worse', 'to', 'breathe', 'now', 'that', 'i', 'm', 'lying', 'down', 'd1', 'is', 'it', 'p1', 'it', 'really', 'hurts', 'when', 'i', 'breathe', 'in', 'd1', 'okay', 'em', 'n1', 'inaudible', 'pr11', 'stick', 'on', 'a', 'mask', 'd1', 'do', 'you', 'n1',\",\n",
       " \"'i', 've', 'peripheral', 'cultures', 'fec', 'pr8', 'smac', 'twenty', 'cop', 'and', 'eh', 'inaudibl', 'pr9', 'e', 'pr10', 'p1', 'i', 'm', 'really', 'finding', '\",\n",
       " \"'i', 'm', 'really', 'finding', '\",\n",
       " \"it', 'hard', 'to', 'breathe', 'd1', '\",\n",
       " 'you',\n",
       " 'we',\n",
       " 'you',\n",
       " 'it',\n",
       " 'it',\n",
       " \"'i', 'm',\",\n",
       " 'it',\n",
       " 'it',\n",
       " 'i',\n",
       " \"'okay', 'em', '\",\n",
       " 'you',\n",
       " 'you',\n",
       " 'me',\n",
       " 'you',\n",
       " 'her',\n",
       " 'you',\n",
       " \"i'\",\n",
       " 'you',\n",
       " 'we',\n",
       " 'her',\n",
       " 'she',\n",
       " \"she'\",\n",
       " 'she',\n",
       " 'they',\n",
       " \"'they',\",\n",
       " 'you',\n",
       " \"'we'\",\n",
       " \"her',\",\n",
       " 'you',\n",
       " \"you'\",\n",
       " \"her'\",\n",
       " 'you',\n",
       " \"'i', 'm'\",\n",
       " 'you',\n",
       " \"'i'\",\n",
       " \"'you'\",\n",
       " 'you',\n",
       " 'it',\n",
       " 'i',\n",
       " 'it',\n",
       " \"'i', 'll', 'set', 'that\",\n",
       " 'you',\n",
       " 'you',\n",
       " \"'i'\",\n",
       " \"you'\",\n",
       " \"i',\",\n",
       " 'you',\n",
       " 'she',\n",
       " 'em',\n",
       " 'i',\n",
       " 'you',\n",
       " 'em',\n",
       " 'em',\n",
       " 'we',\n",
       " 'you',\n",
       " 'me',\n",
       " 'you',\n",
       " \"'em', 'n1'\",\n",
       " \"'i', 'll'\",\n",
       " \"'her', 'oxygen', 'there', 'for', 'you', 'd1', 'yeah', 'n1', 'and', 'her', 'temperature', 'd1', 'and', 'would', 'you', 'be', 'able', 'to', 'help', 'me', 'have', 'a', 'look', 'at', 'her', 'wound', 'as', 'well', 'n1', 'you', 'd', 'like', 'to', 'look', 'at', 'the', 'wound', 'a', 'bit', 'd1', 'yeah', 'n1', 'yeah', 'no', 'problem', 'i', 'll', 'get', 'you', 'a', 'kit', 'for', 'that.', 'd1', 'and', 'can', 'i', 'grab', 'a', 'pair', 'of', 'gloves', 'as', 'well', 'please', 'n1', 'yeah', 'they', 're', 'just', 'around', 'the', 'other', 'side', 'of', 'the', 'bed', 'there', 'd2', 'pair', 'of', 'gloves', 'd1', 'yeah', 'p1', 'did', 'something', 'go', 'wrong', 'with', 'the', 'surgery', 'what', 's', 'going', 'on', 'd1', 'i', 'm', 'just', 'checking', 'the', 'wound', 'now', 'to', 'make', 'sure', 'everything', 's', 'okay', 'p1', 'is', 'everything', 'okay', 'did', 'everything', 'go', 'okay', 'd1', 'the', 'sur…', 'p1', 'am', 'i', 'having', 'a', 'heart', 'attack', 'd1', 'no', 'you', 're', 'not\",\n",
       " 'you',\n",
       " \"'her\",\n",
       " 'you',\n",
       " 'me',\n",
       " 'her',\n",
       " 'you',\n",
       " \"'i'\",\n",
       " 'you',\n",
       " \"'i', 'grab', 'a', 'pair', 'of', 'gloves', 'as', 'well', 'please', 'n1', 'yeah', 'they', 're', 'just', 'around', 'the', 'other', 'side', 'of', 'the', 'bed', 'there', 'd2', 'pair', 'of', 'gloves', 'd1', 'yeah', 'p1',\",\n",
       " \"they'\",\n",
       " \"'i', 'm'\",\n",
       " 'i',\n",
       " \"'you', 're', 'not\",\n",
       " 'you',\n",
       " \"'i',\",\n",
       " \"'i', 'm',\",\n",
       " 'you',\n",
       " 'i',\n",
       " \"i',\",\n",
       " 'you',\n",
       " \"'can', 'you'\",\n",
       " 'you',\n",
       " 'i',\n",
       " 'she',\n",
       " \"'i', 'm', 'not', 'a', 'hundred', 'per', 'cent', 'sure', 'yet', 'mrs', 'o', 'shaughnessy', 'but'\",\n",
       " \"'i', 'm', 'going', 'to', 'check', 'now', 'and', 'i', 'm', 'going', 'to', 'try', 'my', 'best', 'to', 'find', 'out', 'we', 've', 'sent', 'some', 'bloods', 'and', 'we', 're\",\n",
       " \"'i', 'm', 'going', 'to', 'try', 'my', 'best', 'to', 'find', 'out', 'we', 've', 'sent', 'some', 'bloods', 'and', 'we', 're\",\n",
       " \"'we', 've', 'sent',\",\n",
       " 'we',\n",
       " \"it'\",\n",
       " 'i',\n",
       " \"em'\",\n",
       " 'you',\n",
       " 'you',\n",
       " 'you',\n",
       " 'you',\n",
       " \"'i'\",\n",
       " 'it',\n",
       " 'you',\n",
       " 'em',\n",
       " \"i'\",\n",
       " 'you',\n",
       " \"her'\",\n",
       " \"'you', 'tell', 'me', 'if', 'there', 's', 'any', 'pain', 'in', 'the', 'tummy', 'i', 'm', 'going', 'to', 'just', 'have', 'a', 'press\",\n",
       " 'me',\n",
       " \"'i', 'm', 'going', 'to', 'just', 'have', 'a', 'press\",\n",
       " 'it',\n",
       " \"'i', 'm', 'just', 'down', 'here', 'on', 'the', 'post-op', 'surgical', 'ward', 'i', 'wonder', 'could', 'i', 'request', 'a', 'portable', 'chest', 'x-ray', 'for', 'mrs', 'o', 'shaughnessy', 'inaudible', 'pr20', 'p1', 'ow.', 'n1', 'thank', 'you', 'd1', 'that', 's', 'sore', 'there', 'is', 'it', 'p1', 'a', 'little', 'bit.', 'n1', 'that', 'chest', 'x-ray', 's', 'ordered', 'em', 'blood', 'pressure', 's', 'not', 'great', 'she', 's', 'still', 'not', 'great.', 'd1', 'yeah', 'no.', 'n1'\",\n",
       " \"'i'\",\n",
       " \"'i'\",\n",
       " 'you',\n",
       " 'it',\n",
       " \"em',\",\n",
       " 'she',\n",
       " 'i',\n",
       " 'you',\n",
       " \"'i'\",\n",
       " \"'we'\",\n",
       " 'you',\n",
       " 'her',\n",
       " 'it',\n",
       " 'it',\n",
       " \"i'\",\n",
       " 'you',\n",
       " \"i', 'could'\",\n",
       " \"'i'\",\n",
       " 'we',\n",
       " 'her',\n",
       " \"i', 'm', 'freezing', 'd1', 'as', 'well.'\",\n",
       " \"i'\",\n",
       " 'you',\n",
       " 'you',\n",
       " \"'i',\",\n",
       " \"'i'\",\n",
       " 'you',\n",
       " 'it',\n",
       " \"'i'\",\n",
       " \"'i',\",\n",
       " \"'yeah', 'i', 'i', 'want', 'to', 'check', 'the', 'i', 'll', 'check', 'the', 'app', 'pr21', 'first', 'but', 'it', 's…', 'n1', 'great', 'yeah', 'i', 'think', 'there', 's', 'a', 'little…', 'd1', 'there', 's', 'a', 'little', 'book', 'there', 'n1', 'there', 'd2', 'i', 'have', 'my', 'phone', 'as', 'well', 'inaudible', 'n1', 'great', 'd2', 'what', 's', 'it', 'em', 'i', 'm', 'going', 'to', 'do', 'the', 'venous', 'bloods', 'and', 'sample', 'now', 'okay', 'd1', 'yeah', 'perfect', 'n1', 'em', 'just', 'conscious', 'of', 'those', 'observations', 'do', 'you', 'want', 'to', 'ring', 'the', 'reg', 'p1', 'oh', 'i', 'feel', 'very', 'lightheaded.'\",\n",
       " 'i',\n",
       " \"'i'\",\n",
       " \"'it'\",\n",
       " \"'i'\",\n",
       " 'i',\n",
       " 'it',\n",
       " \"'em', 'i', 'm', 'going', 'to', 'do', 'the', 'venous', 'bloods', 'and', 'sample', 'now', 'okay', 'd1', 'yeah', 'perfect', 'n1', 'em', 'just', 'conscious', 'of', 'those', 'observations', 'do', 'you', 'want', 'to', 'ring', 'the', 'reg', 'p1', 'oh', 'i', 'feel', 'very', 'lightheaded\",\n",
       " \"'i', 'm', 'going', 'to', 'do', 'the', 'venous', 'bloods', 'and', 'sample', 'now', 'okay', 'd1', 'yeah', 'perfect', 'n1', 'em', 'just', 'conscious', 'of', 'those', 'observations', 'do', 'you', 'want', 'to', 'ring', 'the', 'reg', 'p1', 'oh', 'i', 'feel', 'very', 'lightheaded\",\n",
       " 'em',\n",
       " 'you',\n",
       " \"'i'\",\n",
       " 'i',\n",
       " 'you',\n",
       " 'you',\n",
       " 'you',\n",
       " 'you',\n",
       " \"'we'\",\n",
       " \"you', 'comfortable'\",\n",
       " 'you',\n",
       " \"'i',\",\n",
       " 'you',\n",
       " 'i',\n",
       " \"'really', 'okay', 'i'\",\n",
       " \"'we',\",\n",
       " \"'em'\",\n",
       " \"i',\",\n",
       " 'i',\n",
       " \"'they'\",\n",
       " 'you',\n",
       " \"'we'\",\n",
       " \"'i', 'm'\",\n",
       " \"', 'ours', 'up'\",\n",
       " 'she',\n",
       " \"i', 'm', 'just', 'getting', 'you', 'some', 'more', 'oxygen', 'now', 'mrs', 'o', 'shaughnessy', 'okay', 'and',\",\n",
       " \"'just', 'getting', 'you'\",\n",
       " 'you',\n",
       " \"'her', 'and'\",\n",
       " \"she'\",\n",
       " 'you',\n",
       " 'me',\n",
       " 'her',\n",
       " 'you',\n",
       " \"me'\",\n",
       " 'you',\n",
       " \"'me', 'mrs', 'o', 'shaughnessy', 'p1', 'eh', 'd1', 'okay', 'inaudible', 'pr30', 'n1', 'you', 'can', 'okay.', 'alright', 'i', 'll', 'just', 'get', 'this', 'oxygen', 'on', 'd2', 'so', 'is', 'the', 'airway', 'okay', 'n1', 'yeah', 'r1', 'okay', 'responding', 'okay', 'n1', 'she', 's', 'just', 'responded', 'to', 'me', 'there', 'yeah', 'yeah', 'd1', 'inaudible', 'pr31', 'n1', 'you', 're', 'getting', 'an', 'abg', 'there', 'd2', 'yeah', 'n1', 'is', 'it', 'okay', 'great', 'alright', 'mrs', 'o', 'shaughnessy', 'we', 're', 'just', 'getting', 'you', 'organised', 'p1', 'eh', 'n1', 'set', 'd2', 'i', 'm', 'i', 'm',\",\n",
       " 'you',\n",
       " \"'i', 'll'\",\n",
       " \"'she', 's', 'just', 'responded', 'to', 'me', 'there', 'yeah', 'yeah', 'd1', 'inaudible', 'pr31', 'n1', 'you', 're', 'getting', 'an', 'abg', 'there', 'd2', 'yeah', 'n1', 'is', 'it', 'okay', 'great', 'alright', 'mrs', 'o', 'shaughnessy', 'we', 're', 'just', 'getting', 'you', 'organised', 'p1', 'eh', 'n1', 'set', 'd2', '\",\n",
       " 'me',\n",
       " 'you',\n",
       " 'it',\n",
       " \"we',\",\n",
       " \"'you', 'organised', 'p1', 'eh',\",\n",
       " \"i', 'm'\",\n",
       " \"'i', 'm',\",\n",
       " \"'you', 'rather', 'me', 'do', 'an', 'arterial', 'blood', 'sample', 'or…', 'r1', 'em', 'i'\",\n",
       " 'me',\n",
       " \"'em', 'i'\",\n",
       " \"'i'\",\n",
       " \"'i'\",\n",
       " 'they',\n",
       " \"i'\",\n",
       " 'they',\n",
       " \"'em',\",\n",
       " \"'em', 'em', 'i'\",\n",
       " \"'i'\",\n",
       " 'we',\n",
       " 'you',\n",
       " 'em',\n",
       " 'em',\n",
       " 'we',\n",
       " 'it',\n",
       " \"we'\",\n",
       " 'it',\n",
       " 'you',\n",
       " \"'it',\",\n",
       " \"'it',\",\n",
       " 'we',\n",
       " 'we',\n",
       " 'you',\n",
       " \"'we',\",\n",
       " 'you',\n",
       " 'you',\n",
       " 'you',\n",
       " 'you',\n",
       " \"we'\",\n",
       " \"we', 'have'\",\n",
       " \", 'hello', 'd2', 'surgical', 'd1', 'i'\",\n",
       " 'you',\n",
       " 'her',\n",
       " 'you',\n",
       " 'you',\n",
       " \"'you', 'hear', 'me', 'f3', 'inaudible', 'pr37', 'd1', 'sorry', 'inaudible', 'pr38', 'n1', 'just', 'the', 'obs', 'again', 'there', 'so', 'one', 'three', 'five', 'now', 'the', 'heart', 'rate', 'sats', '\",\n",
       " \"'we'\",\n",
       " 'you',\n",
       " 'you',\n",
       " \"me'\",\n",
       " 'you',\n",
       " 'it',\n",
       " \"'you', 'chart', 'that', 'd2', 'yeah', 'd2', 'perfect', 'd1', 'em', 'and\",\n",
       " \", 'd1', 'em', 'and\",\n",
       " \"i', 'can'\",\n",
       " 'you',\n",
       " 'she',\n",
       " \"'i'\",\n",
       " 'she',\n",
       " \"'we'\",\n",
       " \"i', 'd2', '\",\n",
       " \"she'\",\n",
       " 'her',\n",
       " 'she',\n",
       " \"', 'abg', 'do', 'you'\",\n",
       " \"me'\",\n",
       " \"i'\",\n",
       " 'it',\n",
       " 'you',\n",
       " 'it',\n",
       " \"i'\",\n",
       " 'it',\n",
       " 'you',\n",
       " \"'i', 'd1',\",\n",
       " 'she',\n",
       " 'she',\n",
       " \"she'\",\n",
       " 'she',\n",
       " 'it',\n",
       " 'em',\n",
       " 'we',\n",
       " \"'i'\",\n",
       " \"'we', 'should'\",\n",
       " 'you',\n",
       " \"'i',\",\n",
       " 'them',\n",
       " 'you',\n",
       " 'them',\n",
       " 'they',\n",
       " \"you'\",\n",
       " 'you',\n",
       " 'you',\n",
       " 'me',\n",
       " 'you',\n",
       " 'her',\n",
       " 'it',\n",
       " \"'her', 'urine', 'output', 'd2', 'em', 'so', 'd1', 'just', 'regards', 'the', 'urine', 'output',\",\n",
       " \"'em', 'so', 'd1', 'just\",\n",
       " 'it',\n",
       " 'we',\n",
       " 'it',\n",
       " 'she',\n",
       " 'you',\n",
       " 'you',\n",
       " 'she',\n",
       " \"'i'\",\n",
       " 'she',\n",
       " \"she'\",\n",
       " 'you',\n",
       " \"me'\",\n",
       " 'she',\n",
       " 'you',\n",
       " 'she',\n",
       " 'she',\n",
       " \"'em', '\",\n",
       " \"you'\",\n",
       " \"'you'\",\n",
       " 'you',\n",
       " 'me',\n",
       " \"'the', 'avg', 'd2', 'em', 'yeah'\",\n",
       " 'i',\n",
       " 'you',\n",
       " 'em',\n",
       " 'it',\n",
       " 'em',\n",
       " 'it',\n",
       " 'em',\n",
       " \"it', 's', 'important', 'em'\",\n",
       " \", 's', 'important', 'em'\",\n",
       " 'we',\n",
       " \"', 're-reassess', 'we',\",\n",
       " \"'we', 've', 'given', 'her',\",\n",
       " \"'her',\",\n",
       " \"'em',\",\n",
       " \"'her\",\n",
       " 'it',\n",
       " 'it',\n",
       " 'it',\n",
       " 'it',\n",
       " 'em',\n",
       " 'it',\n",
       " 'em',\n",
       " 'you',\n",
       " 'you',\n",
       " \"'her', 'the', 'antibiotics', '\",\n",
       " 'you',\n",
       " 'em',\n",
       " 'they',\n",
       " 'i',\n",
       " \"'em'\",\n",
       " \"'i'\",\n",
       " 'she',\n",
       " \"em'\",\n",
       " 'you',\n",
       " \"'we'\",\n",
       " 'her',\n",
       " 'we',\n",
       " 'we',\n",
       " 'we',\n",
       " 'we',\n",
       " 'me',\n",
       " \"'we',\",\n",
       " 'her',\n",
       " 'her',\n",
       " 'she',\n",
       " 'em',\n",
       " \"she'\",\n",
       " \"she'\",\n",
       " 'it',\n",
       " \"i'\",\n",
       " 'you',\n",
       " \"we', 'll'\",\n",
       " 'you',\n",
       " 'we',\n",
       " \"you'\",\n",
       " 'you',\n",
       " 'it',\n",
       " 'you',\n",
       " \"'we',\",\n",
       " \"'i', 'might'\",\n",
       " 'you',\n",
       " \"'i',\",\n",
       " 'you',\n",
       " \"'i',\",\n",
       " \"'i'\",\n",
       " \"i', 'll'\",\n",
       " 'you',\n",
       " 'it',\n",
       " 'it',\n",
       " \"'i'\",\n",
       " \"'i', 'just'\",\n",
       " \"'i'\",\n",
       " 'you',\n",
       " 'we',\n",
       " \"'i', 'm',\",\n",
       " \"'i', 'll'\",\n",
       " 'you',\n",
       " \"'we'\",\n",
       " \"you'\",\n",
       " 'you',\n",
       " 'i',\n",
       " \"'i'\",\n",
       " 'i',\n",
       " 'him',\n",
       " 'you',\n",
       " \"you'\",\n",
       " 'you',\n",
       " \"'i', 'am', 'sixty-eight', 'd1', 'sixty-eight', 'p1', 'years', 'young', 'pause'\",\n",
       " \"'i'\",\n",
       " 'you',\n",
       " 'she',\n",
       " \"'she'\",\n",
       " \"she', 's'\",\n",
       " 'em',\n",
       " \"'her\",\n",
       " \"'her',\",\n",
       " 'you',\n",
       " \"'you'\",\n",
       " \"'we', 'have', 'a', 'full', 'blood', 'count', 'smac', 'twenty', 'eh', 'cop', 'cultures', 'and', 'coag'\",\n",
       " 'her',\n",
       " 'you',\n",
       " 'you',\n",
       " \"'you', 'rather', 'me'\",\n",
       " \"'me'\",\n",
       " 'you',\n",
       " \"'i',\",\n",
       " \"'i',\",\n",
       " \"'i'\",\n",
       " \"'you'\",\n",
       " 'you',\n",
       " \"we'\",\n",
       " 'you',\n",
       " 'you',\n",
       " 'she',\n",
       " \"she'\",\n",
       " 'em',\n",
       " \"i', 'have', 'her', 'just'\",\n",
       " \"'her', 'just'\",\n",
       " 'you',\n",
       " 'she',\n",
       " \"she'\",\n",
       " \"i'\",\n",
       " 'she',\n",
       " 'you',\n",
       " 'she',\n",
       " 'we',\n",
       " 'you',\n",
       " 'it',\n",
       " \"'i', 'd', 'like…', 'p1', 'i', 'm', 'finding', 'it', 'hard', 'to', 'breathe.'\",\n",
       " \"'i', 'm', 'finding', 'it', 'hard', 'to', 'breathe\",\n",
       " \"'it'\",\n",
       " 'you',\n",
       " \"it', 'hard', 'to', 'breathe',\",\n",
       " 'you',\n",
       " \"we', 'll'\",\n",
       " 'you',\n",
       " \"i'\",\n",
       " 'you',\n",
       " \"'i', 'get', 'some', 'nasal', 'cannula', 'just', 'for', 'mrs', 'o', 'shaughnessy', 'she', 's', 'finding', 'it', 'a', 'little', 'bit', 'hard', 'to', 'breathe', 'n1', 'sure.', 'no', 'problem', 'no', 'problem', 'i', 'll', 'just', 'finish', 'these', 'bloods', 'for', 'you', 'and\",\n",
       " 'she',\n",
       " 'it',\n",
       " \"'i', 'll', 'just', 'finish', 'these', 'bloods', 'for', 'you', 'and\",\n",
       " \"'you', 'and\",\n",
       " \"'i'\",\n",
       " 'we',\n",
       " \"'her', 'down', 'flat'\",\n",
       " \"i'\",\n",
       " 'you',\n",
       " 'it',\n",
       " \"i'\",\n",
       " 'you',\n",
       " \"i'\",\n",
       " 'you',\n",
       " 'i',\n",
       " \"'we',\",\n",
       " 'you',\n",
       " \"'i', 've', 'those', 'blood', 'tests', 'done', 'there', 'so', 'i', 've', 'peripheral', 'cultures', 'fec', 'pr8', 'smac', 'twenty', 'cop', 'and', 'eh', 'inaudibl', 'pr9', 'e', 'pr10', 'p1', 'i', 'm', 'really', 'finding', 'it', 'hard', 'to', 'breathe', 'd1', 'that', 's', 'great', 'thank', 'you', 'very', 'much', 'we', 're', 'going', 'to', 'get', 'you', 'a', 'little', 'bit', 'of', 'oxygen', 'now', 'and', 'that', 'should', 'help', 'with', 'the', 'the', 'feeling', 'of', 'shortness', 'of', 'breath', 'okay', 'pause', 'p1', 'oh', 'it', 's', 'really', 'it', 's', 'getting', 'worse', 'to', 'breathe', 'now', 'that', 'i', 'm', 'lying', 'down', 'd1', 'is', 'it', 'p1', 'it', 'really', 'hurts', 'when', 'i', 'breathe', 'in', 'd1', 'okay', 'em', 'n1', 'inaudible', 'pr11', 'stick', 'on', 'a', 'mask', 'd1', 'do', 'you', 'n1',\",\n",
       " \"'i', 've', 'peripheral', 'cultures', 'fec', 'pr8', 'smac', 'twenty', 'cop', 'and', 'eh', 'inaudibl', 'pr9', 'e', 'pr10', 'p1', 'i', 'm', 'really', 'finding', '\",\n",
       " \"'i', 'm', 'really', 'finding', '\",\n",
       " \"it', 'hard', 'to', 'breathe', 'd1', '\",\n",
       " 'you',\n",
       " 'we',\n",
       " 'you',\n",
       " 'it',\n",
       " 'it',\n",
       " \"'i', 'm',\",\n",
       " 'it',\n",
       " 'it',\n",
       " 'i',\n",
       " \"'okay', 'em', '\",\n",
       " 'you',\n",
       " 'you',\n",
       " 'me',\n",
       " 'you',\n",
       " 'her',\n",
       " 'you',\n",
       " \"i'\",\n",
       " 'you',\n",
       " 'we',\n",
       " 'her',\n",
       " 'she',\n",
       " \"she'\",\n",
       " 'she',\n",
       " 'they',\n",
       " \"'they',\",\n",
       " 'you',\n",
       " \"'we'\",\n",
       " \"her',\",\n",
       " 'you',\n",
       " \"you'\",\n",
       " \"her'\",\n",
       " 'you',\n",
       " \"'i', 'm'\",\n",
       " 'you',\n",
       " \"'i'\",\n",
       " \"'you'\",\n",
       " 'you',\n",
       " 'it',\n",
       " 'i',\n",
       " 'it',\n",
       " \"'i', 'll', 'set', 'that\",\n",
       " 'you',\n",
       " 'you',\n",
       " \"'i'\",\n",
       " \"you'\",\n",
       " \"i',\",\n",
       " 'you',\n",
       " 'she',\n",
       " 'em',\n",
       " 'i',\n",
       " 'you',\n",
       " 'em',\n",
       " 'em',\n",
       " 'we',\n",
       " 'you',\n",
       " 'me',\n",
       " 'you',\n",
       " \"'em', 'n1'\",\n",
       " \"'i', 'll'\",\n",
       " \"'her', 'oxygen', 'there', 'for', 'you', 'd1', 'yeah', 'n1', 'and', 'her', 'temperature', 'd1', 'and', 'would', 'you', 'be', 'able', 'to', 'help', 'me', 'have', 'a', 'look', 'at', 'her', 'wound', 'as', 'well', 'n1', 'you', 'd', 'like', 'to', 'look', 'at', 'the', 'wound', 'a', 'bit', 'd1', 'yeah', 'n1', 'yeah', 'no', 'problem', 'i', 'll', 'get', 'you', 'a', 'kit', 'for', 'that.', 'd1', 'and', 'can', 'i', 'grab', 'a', 'pair', 'of', 'gloves', 'as', 'well', 'please', 'n1', 'yeah', 'they', 're', 'just', 'around', 'the', 'other', 'side', 'of', 'the', 'bed', 'there', 'd2', 'pair', 'of', 'gloves', 'd1', 'yeah', 'p1', 'did', 'something', 'go', 'wrong', 'with', 'the', 'surgery', 'what', 's', 'going', 'on', 'd1', 'i', 'm', 'just', 'checking', 'the', 'wound', 'now', 'to', 'make', 'sure', 'everything', 's', 'okay', 'p1', 'is', 'everything', 'okay', 'did', 'everything', 'go', 'okay', 'd1', 'the', 'sur…', 'p1', 'am', 'i', 'having', 'a', 'heart', 'attack', 'd1', 'no', 'you', 're', 'not\",\n",
       " 'you',\n",
       " \"'her\",\n",
       " 'you',\n",
       " 'me',\n",
       " 'her',\n",
       " 'you',\n",
       " \"'i'\",\n",
       " 'you',\n",
       " \"'i', 'grab', 'a', 'pair', 'of', 'gloves', 'as', 'well', 'please', 'n1', 'yeah', 'they', 're', 'just', 'around', 'the', 'other', 'side', 'of', 'the', 'bed', 'there', 'd2', 'pair', 'of', 'gloves', 'd1', 'yeah', 'p1',\",\n",
       " \"they'\",\n",
       " \"'i', 'm'\",\n",
       " 'i',\n",
       " \"'you', 're', 'not\",\n",
       " 'you',\n",
       " \"'i',\",\n",
       " \"'i', 'm',\",\n",
       " 'you',\n",
       " 'i',\n",
       " \"i',\",\n",
       " 'you',\n",
       " \"'can', 'you'\",\n",
       " 'you',\n",
       " 'i',\n",
       " 'she',\n",
       " \"'i', 'm', 'not', 'a', 'hundred', 'per', 'cent', 'sure', 'yet', 'mrs', 'o', 'shaughnessy', 'but'\",\n",
       " \"'i', 'm', 'going', 'to', 'check', 'now', 'and', 'i', 'm', 'going', 'to', 'try', 'my', 'best', 'to', 'find', 'out', 'we', 've', 'sent', 'some', 'bloods', 'and', 'we', 're\",\n",
       " \"'i', 'm', 'going', 'to', 'try', 'my', 'best', 'to', 'find', 'out', 'we', 've', 'sent', 'some', 'bloods', 'and', 'we', 're\",\n",
       " \"'we', 've', 'sent',\",\n",
       " 'we',\n",
       " \"it'\",\n",
       " 'i',\n",
       " \"em'\",\n",
       " 'you',\n",
       " 'you',\n",
       " 'you',\n",
       " 'you',\n",
       " \"'i'\",\n",
       " 'it',\n",
       " 'you',\n",
       " 'em',\n",
       " \"i'\",\n",
       " 'you',\n",
       " \"her'\",\n",
       " \"'you', 'tell', 'me', 'if', 'there', 's', 'any', 'pain', 'in', 'the', 'tummy', 'i', 'm', 'going', 'to', 'just', 'have', 'a', 'press\",\n",
       " 'me',\n",
       " \"'i', 'm', 'going', 'to', 'just', 'have', 'a', 'press\",\n",
       " 'it',\n",
       " \"'i', 'm', 'just', 'down', 'here', 'on', 'the', 'post-op', 'surgical', 'ward', 'i', 'wonder', 'could', 'i', 'request', 'a', 'portable', 'chest', 'x-ray', 'for', 'mrs', 'o', 'shaughnessy', 'inaudible', 'pr20', 'p1', 'ow.', 'n1', 'thank', 'you', 'd1', 'that', 's', 'sore', 'there', 'is', 'it', 'p1', 'a', 'little', 'bit.', 'n1', 'that', 'chest', 'x-ray', 's', 'ordered', 'em', 'blood', 'pressure', 's', 'not', 'great', 'she', 's', 'still', 'not', 'great.', 'd1', 'yeah', 'no.', 'n1'\",\n",
       " \"'i'\",\n",
       " \"'i'\",\n",
       " 'you',\n",
       " 'it',\n",
       " \"em',\",\n",
       " 'she',\n",
       " 'i',\n",
       " 'you',\n",
       " \"'i'\",\n",
       " \"'we'\",\n",
       " 'you',\n",
       " 'her',\n",
       " 'it',\n",
       " 'it',\n",
       " \"i'\",\n",
       " 'you',\n",
       " \"i', 'could'\",\n",
       " \"'i'\",\n",
       " 'we',\n",
       " 'her',\n",
       " \"i', 'm', 'freezing', 'd1', 'as', 'well.'\",\n",
       " \"i'\",\n",
       " 'you',\n",
       " 'you',\n",
       " \"'i',\",\n",
       " \"'i'\",\n",
       " 'you',\n",
       " 'it',\n",
       " \"'i'\",\n",
       " \"'i',\",\n",
       " \"'yeah', 'i', 'i', 'want', 'to', 'check', 'the', 'i', 'll', 'check', 'the', 'app', 'pr21', 'first', 'but', 'it', 's…', 'n1', 'great', 'yeah', 'i', 'think', 'there', 's', 'a', 'little…', 'd1', 'there', 's', 'a', 'little', 'book', 'there', 'n1', 'there', 'd2', 'i', 'have', 'my', 'phone', 'as', 'well', 'inaudible', 'n1', 'great', 'd2', 'what', 's', 'it', 'em', 'i', 'm', 'going', 'to', 'do', 'the', 'venous', 'bloods', 'and', 'sample', 'now', 'okay', 'd1', 'yeah', 'perfect', 'n1', 'em', 'just', 'conscious', 'of', 'those', 'observations', 'do', 'you', 'want', 'to', 'ring', 'the', 'reg', 'p1', 'oh', 'i', 'feel', 'very', 'lightheaded.'\",\n",
       " 'i',\n",
       " \"'i'\",\n",
       " \"'it'\",\n",
       " \"'i'\",\n",
       " 'i',\n",
       " 'it',\n",
       " \"'em', 'i', 'm', 'going', 'to', 'do', 'the', 'venous', 'bloods', 'and', 'sample', 'now', 'okay', 'd1', 'yeah', 'perfect', 'n1', 'em', 'just', 'conscious', 'of', 'those', 'observations', 'do', 'you', 'want', 'to', 'ring', 'the', 'reg', 'p1', 'oh', 'i', 'feel', 'very', 'lightheaded\",\n",
       " \"'i', 'm', 'going', 'to', 'do', 'the', 'venous', 'bloods', 'and', 'sample', 'now', 'okay', 'd1', 'yeah', 'perfect', 'n1', 'em', 'just', 'conscious', 'of', 'those', 'observations', 'do', 'you', 'want', 'to', 'ring', 'the', 'reg', 'p1', 'oh', 'i', 'feel', 'very', 'lightheaded\",\n",
       " 'em',\n",
       " 'you',\n",
       " \"'i'\",\n",
       " 'i',\n",
       " 'you',\n",
       " 'you',\n",
       " 'you',\n",
       " 'you',\n",
       " \"'we'\",\n",
       " \"you', 'comfortable'\",\n",
       " 'you',\n",
       " \"'i',\",\n",
       " 'you',\n",
       " 'i',\n",
       " \"'really', 'okay', 'i'\",\n",
       " \"'we',\",\n",
       " \"'em'\",\n",
       " \"i',\",\n",
       " 'i',\n",
       " \"'they'\",\n",
       " 'you',\n",
       " \"'we'\",\n",
       " \"'i', 'm'\",\n",
       " \"', 'ours', 'up'\",\n",
       " 'she',\n",
       " \"i', 'm', 'just', 'getting', 'you', 'some', 'more', 'oxygen', 'now', 'mrs', 'o', 'shaughnessy', 'okay', 'and',\",\n",
       " \"'just', 'getting', 'you'\",\n",
       " 'you',\n",
       " \"'her', 'and'\",\n",
       " \"she'\",\n",
       " 'you',\n",
       " 'me',\n",
       " 'her',\n",
       " 'you',\n",
       " \"me'\",\n",
       " 'you',\n",
       " \"'me', 'mrs', 'o', 'shaughnessy', 'p1', 'eh', 'd1', 'okay', 'inaudible', 'pr30', 'n1', 'you', 'can', 'okay.', 'alright', 'i', 'll', 'just', 'get', 'this', 'oxygen', 'on', 'd2', 'so', 'is', 'the', 'airway', 'okay', 'n1', 'yeah', 'r1', 'okay', 'responding', 'okay', 'n1', 'she', 's', 'just', 'responded', 'to', 'me', 'there', 'yeah', 'yeah', 'd1', 'inaudible', 'pr31', 'n1', 'you', 're', 'getting', 'an', 'abg', 'there', 'd2', 'yeah', 'n1', 'is', 'it', 'okay', 'great', 'alright', 'mrs', 'o', 'shaughnessy', 'we', 're', 'just', 'getting', 'you', 'organised', 'p1', 'eh', 'n1', 'set', 'd2', 'i', 'm', 'i', 'm',\",\n",
       " 'you',\n",
       " \"'i', 'll'\",\n",
       " \"'she', 's', 'just', 'responded', 'to', 'me', 'there', 'yeah', 'yeah', 'd1', 'inaudible', 'pr31', 'n1', 'you', 're', 'getting', 'an', 'abg', 'there', 'd2', 'yeah', 'n1', 'is', 'it', 'okay', 'great', 'alright', 'mrs', 'o', 'shaughnessy', 'we', 're', 'just', 'getting', 'you', 'organised', 'p1', 'eh', 'n1', 'set', 'd2', '\",\n",
       " 'me',\n",
       " 'you',\n",
       " 'it',\n",
       " \"we',\",\n",
       " \"'you', 'organised', 'p1', 'eh',\",\n",
       " \"i', 'm'\",\n",
       " \"'i', 'm',\",\n",
       " \"'you', 'rather', 'me', 'do', 'an', 'arterial', 'blood', 'sample', 'or…', 'r1', 'em', 'i'\",\n",
       " 'me',\n",
       " \"'em', 'i'\",\n",
       " \"'i'\",\n",
       " \"'i'\",\n",
       " 'they',\n",
       " \"i'\",\n",
       " 'they',\n",
       " \"'em',\",\n",
       " \"'em', 'em', 'i'\",\n",
       " \"'i'\",\n",
       " 'we',\n",
       " 'you',\n",
       " 'em',\n",
       " 'em',\n",
       " 'we',\n",
       " 'it',\n",
       " \"we'\",\n",
       " 'it',\n",
       " 'you',\n",
       " \"'it',\",\n",
       " \"'it',\",\n",
       " 'we',\n",
       " 'we',\n",
       " 'you',\n",
       " \"'we',\",\n",
       " 'you',\n",
       " 'you',\n",
       " 'you',\n",
       " 'you',\n",
       " \"we'\",\n",
       " \"we', 'have'\",\n",
       " \", 'hello', 'd2', 'surgical', 'd1', 'i'\",\n",
       " 'you',\n",
       " 'her',\n",
       " 'you',\n",
       " 'you',\n",
       " \"'you', 'hear', 'me', 'f3', 'inaudible', 'pr37', 'd1', 'sorry', 'inaudible', 'pr38', 'n1', 'just', 'the', 'obs', 'again', 'there', 'so', 'one', 'three', 'five', 'now', 'the', 'heart', 'rate', 'sats', '\",\n",
       " \"'we'\",\n",
       " 'you',\n",
       " 'you',\n",
       " \"me'\",\n",
       " 'you',\n",
       " 'it',\n",
       " \"'you', 'chart', 'that', 'd2', 'yeah', 'd2', 'perfect', 'd1', 'em', 'and\",\n",
       " \", 'd1', 'em', 'and\",\n",
       " \"i', 'can'\",\n",
       " 'you',\n",
       " 'she',\n",
       " \"'i'\",\n",
       " 'she',\n",
       " \"'we'\",\n",
       " \"i', 'd2', '\",\n",
       " \"she'\",\n",
       " 'her',\n",
       " 'she',\n",
       " \"', 'abg', 'do', 'you'\",\n",
       " \"me'\",\n",
       " \"i'\",\n",
       " 'it',\n",
       " 'you',\n",
       " 'it',\n",
       " \"i'\",\n",
       " 'it',\n",
       " 'you',\n",
       " \"'i', 'd1',\",\n",
       " 'she',\n",
       " 'she',\n",
       " \"she'\",\n",
       " 'she',\n",
       " 'it',\n",
       " 'em',\n",
       " 'we',\n",
       " \"'i'\",\n",
       " \"'we', 'should'\",\n",
       " 'you',\n",
       " \"'i',\",\n",
       " 'them',\n",
       " 'you',\n",
       " 'them',\n",
       " 'they',\n",
       " \"you'\",\n",
       " 'you',\n",
       " 'you',\n",
       " 'me',\n",
       " 'you',\n",
       " 'her',\n",
       " 'it',\n",
       " \"'her', 'urine', 'output', 'd2', 'em', 'so', 'd1', 'just', 'regards', 'the', 'urine', 'output',\",\n",
       " \"'em', 'so', 'd1', 'just\",\n",
       " 'it',\n",
       " 'we',\n",
       " 'it',\n",
       " 'she',\n",
       " 'you',\n",
       " 'you',\n",
       " 'she',\n",
       " \"'i'\",\n",
       " 'she',\n",
       " \"she'\",\n",
       " 'you',\n",
       " \"me'\",\n",
       " 'she',\n",
       " 'you',\n",
       " 'she',\n",
       " 'she',\n",
       " \"'em', '\",\n",
       " \"you'\",\n",
       " \"'you'\",\n",
       " 'you',\n",
       " 'me',\n",
       " \"'the', 'avg', 'd2', 'em', 'yeah'\",\n",
       " 'i',\n",
       " 'you',\n",
       " 'em',\n",
       " 'it',\n",
       " 'em',\n",
       " 'it',\n",
       " 'em',\n",
       " \"it', 's', 'important', 'em'\",\n",
       " \", 's', 'important', 'em'\",\n",
       " 'we',\n",
       " \"', 're-reassess', 'we',\",\n",
       " \"'we', 've', 'given', 'her',\",\n",
       " \"'her',\",\n",
       " \"'em',\",\n",
       " \"'her\",\n",
       " 'it',\n",
       " 'it',\n",
       " 'it',\n",
       " 'it',\n",
       " 'em',\n",
       " 'it',\n",
       " 'em',\n",
       " 'you',\n",
       " 'you',\n",
       " \"'her', 'the', 'antibiotics', '\",\n",
       " 'you',\n",
       " 'em',\n",
       " 'they',\n",
       " 'i',\n",
       " \"'em'\",\n",
       " \"'i'\",\n",
       " 'she',\n",
       " \"em'\",\n",
       " 'you',\n",
       " \"'we'\",\n",
       " 'her',\n",
       " 'we',\n",
       " 'we',\n",
       " 'we',\n",
       " 'we',\n",
       " 'me',\n",
       " \"'we',\",\n",
       " 'her',\n",
       " 'her',\n",
       " 'she',\n",
       " 'em',\n",
       " \"she'\",\n",
       " \"she'\"]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\"\\n### adverb\\nword.tag_ == ('RB'):\\n\\n### adjective\\nword.tag_ == ('JJ'):\\n\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = open_and_tokenize(counter, folder)\n",
    "\n",
    "doc = nlp(str(tokens))\n",
    "\n",
    "\n",
    "\n",
    "###################################################################  Active / Passive\n",
    "nsubj_subjects = []\n",
    "nsubj_count    = 0\n",
    "for word in doc:\n",
    "    if word.dep_ == ('nsubj'):\n",
    "        nsubj_count += 1\n",
    "        nsubj_subjects.append(flatten_subtree(word.subtree))\n",
    "nsubj_subjects\n",
    "nsubj_count\n",
    "\n",
    "nsubjpass_subjects = []\n",
    "nsubjpass_count = 0\n",
    "for word in doc:\n",
    "    if word.dep_ == ('nsubjpass'):\n",
    "        nsubjpass_count += 1\n",
    "        nsubjpass_subjects.append(flatten_subtree(word.subtree))\n",
    "nsubjpass_subjects\n",
    "nsubjpass_count\n",
    "\n",
    "################################################################### Parts of speech:\n",
    "pos = {}\n",
    "\n",
    "mylist = [\"verb\", \"personal_pronoun\", \"adverb\", \"adjective\"]\n",
    "\n",
    "for x in mylist:\n",
    "    pos[\"{0}_list\".format(x)] = ''\n",
    "    pos[\"{0}_count\".format(x)] = 0\n",
    "\n",
    "pos\n",
    "\n",
    "temp_list = []\n",
    "for word in doc:\n",
    "    if word.tag_ == ('VBD'):\n",
    "        pos[\"verb_count\"]  +=  1\n",
    "        temp_list.append(flatten_subtree(word.subtree))\n",
    "pos[\"verb_list\"]  = temp_list\n",
    "\n",
    "\n",
    "temp_list = []\n",
    "for word in doc:\n",
    "    if word.tag_ == ('PRP'):\n",
    "        pos[\"personal_pronoun_count\"]  +=  1\n",
    "        temp_list.append(flatten_subtree(word.subtree))\n",
    "        pos[\"personal_pronoun_list\"]  = personal_pronoun_list\n",
    "\n",
    "        \n",
    "print(\"verb_count\")\n",
    "pos[\"verb_count\"]\n",
    "print(\"\")\n",
    "\n",
    "print(\"verb_list\")\n",
    "pos[\"verb_list\"]\n",
    "print(\"\")\n",
    "\n",
    "print(\"personal_pronoun_count\")\n",
    "pos[\"personal_pronoun_count\"]\n",
    "print(\"\")\n",
    "\n",
    "print(\"personal_pronoun_list\")\n",
    "pos[\"personal_pronoun_list\"]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "### adverb\n",
    "word.tag_ == ('RB'):\n",
    "\n",
    "### adjective\n",
    "word.tag_ == ('JJ'):\n",
    "\"\"\"\n",
    "\n",
    "    \n",
    "################################################################### Phrases specified by Robin:\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adjective_count': 0,\n",
       " 'adjective_list': '',\n",
       " 'adverb_count': 0,\n",
       " 'adverb_list': '',\n",
       " 'personal_pronoun_count': 0,\n",
       " 'personal_pronoun_list': '',\n",
       " 'verb_count': 0,\n",
       " 'verb_list': ''}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verb_list': ''}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos= {}\n",
    "pos[\"verb_list\"]        = \"\"\n",
    "pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse content - use procedural code to avoid issues re local / global variables in functional programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##  %run -i sentiment_build_functions.py\n",
    "\n",
    "counter = 0\n",
    "\n",
    "# while counter < no_files:\n",
    "while counter < no_files:\n",
    "    tokens = open_and_tokenize(counter, folder)\n",
    "\n",
    "    ############################################################  Number speakers & words & turns\n",
    "    %run -i count_num_speakers.py\n",
    "    \"\"\"\n",
    "    for content of 'tokens' - add 1 number to end of list \"Num_speakers\"\n",
    "    \"\"\"\n",
    "\n",
    "    %run -i turns_per_speaker.py\n",
    "    \"\"\"\n",
    "    For tokens - add 1 x number to variable for each speaker e.g. \"Num_turns_P1\"\n",
    "    \"\"\"\n",
    "\n",
    "    ############################################################  Positive & Negative sentiment\n",
    "    %run -i pos_neg_score_append.py\n",
    "    \"\"\"\n",
    "    DONE FOR LISTS - MAYBE TRY AS A DICTIONARY?\n",
    "    count number of pos & neg words in each transcript.\n",
    "    for content of 'tokens' - add 1 number to positive_score_list & negative_score_list\n",
    "    \"\"\"\n",
    "    \n",
    "    %run -i pos_neg_words_set_freq.py\n",
    "    \"\"\"\n",
    "    count freq of all pos / neg words across all files.\n",
    "    create a set showing each pos / neg word once\n",
    "    \"\"\"\n",
    "    \n",
    "    ############################################################  Parts of speech\n",
    "    %run -i parts_of_speech.py\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    ############################################################  Active & Passive phrases\n",
    "    %run -i spacy_dep_parse.py\n",
    "    \"\"\"\n",
    "    Active / Passive phrases\n",
    "    \"\"\"\n",
    "    \n",
    "    ############################################################  Alignment / Repetition / Mirroring\n",
    "    %run -i align_package_nickduran_pr.py\n",
    "    \"\"\"\n",
    "    Run Nick Duran's 'align' package on the data.\n",
    "    \"\"\"\n",
    "    \n",
    "    ############################################################  Medical terminology\n",
    "    %run -i count_med_terms.py\n",
    "    \"\"\"\n",
    "    Count the number of medical concepts\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    counter += 1\n",
    "\n",
    "\n",
    "\n",
    "print(positive_num)\n",
    "print(negative_num)\n",
    "print(positive_score_list)\n",
    "print(negative_score_list)\n",
    "\n",
    "print(len(pos_set_all_dialogue))\n",
    "print(pos_set_all_dialogue)\n",
    "print(len(neg_set_all_dialogue))\n",
    "print(neg_set_all_dialogue)\n",
    "\n",
    "x = nltk.FreqDist(pos_freq_all_dialogue)\n",
    "x\n",
    "x = nltk.FreqDist(neg_freq_all_dialogue)\n",
    "x\n",
    "\n",
    "Num_speakers\n",
    "\n",
    "Num_turns_P1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assert vectors are all the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len() == len()  & /\n",
    "       len() == len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assert the functions work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Loop (i.e. repeat for every text file in folder)\n",
    "### open the first text file: tokenise it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### First: define name of file to open\n",
    "file = os.listdir(\"sentiment_text_data\")[0]\n",
    "type(file)\n",
    "file\n",
    "\n",
    "print()\n",
    "print(\"Open file and display 'type'\")\n",
    "f = open(file)\n",
    "type(f)\n",
    "\n",
    "print()\n",
    "print(\"Read file and display 'type'\")\n",
    "f2   = f.read()\n",
    "type(f2)\n",
    "\n",
    "print()\n",
    "print(\"Tokenise file and display 'type'\")\n",
    "### Tokenize the text:\n",
    "tokens = tokenize_only(f2)\n",
    "type(tokens)\n",
    "\n",
    "################################################## run the functions from the other file.\n",
    "loop_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counter = 0\n",
    "\n",
    "# while counter < no_files:\n",
    "open_and_tokenize()\n",
    "tokens[:10]\n",
    "tokens[-10:]\n",
    "\n",
    "pos_neg_lists_append_func()\n",
    "\n",
    "pos_in_this, neg_in_this,  pos_freq_in_this, neg_freq_in_this  =   pos_neg_words_this_file_func()\n",
    "\n",
    "print(\"1\")\n",
    "pos_set_all_dialogue\n",
    "print(\"2\")\n",
    "pos_set_all_dialogue.extend(pos_in_this)\n",
    "print(\"3\")\n",
    "pos_set_all_dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extend_set_all_pos_neg_words_func()\n",
    "\n",
    "\"\"\"\n",
    "count_num_speakers_func()\n",
    "turns_per_speaker_func()   \n",
    "counter = counter + 1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: after loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Positive & Negative word set, Pos & Neg frequency distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_set_all_dialogue\n",
    "%run -i sentiment_pos_neg_results.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentiment_more_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Turn taking: number of words and sentences per speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run sentiment_turn_taking_results.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Active & Passive noun dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run sentiment_active_passive.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
